{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ebd2b2",
   "metadata": {
    "papermill": {
     "duration": 0.019703,
     "end_time": "2022-02-04T08:48:51.999542",
     "exception": false,
     "start_time": "2022-02-04T08:48:51.979839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Triple Stratified KFold CV with TFRecords\n",
    "This is a simple starter notebook for Kaggle's Melanoma Comp showing triple stratifed KFold with TFRecords. Triple stratified KFold is explained [here][2]. There are many configuration variables below to allow you to experiment. Use either GPU or TPU. You can control which size images are loaded, which efficientNets are used, and whether external data is used. You can experiment with different data augmentation, model architecture, loss, optimizers, and learning schedules. The TFRecords contain meta data, so you can input that into your CNN too. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99e113",
   "metadata": {
    "papermill": {
     "duration": 0.017521,
     "end_time": "2022-02-04T08:48:52.035013",
     "exception": false,
     "start_time": "2022-02-04T08:48:52.017492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025e6a1b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-04T08:48:52.077296Z",
     "iopub.status.busy": "2022-02-04T08:48:52.075945Z",
     "iopub.status.idle": "2022-02-04T08:49:01.697825Z",
     "shell.execute_reply": "2022-02-04T08:49:01.697012Z",
     "shell.execute_reply.started": "2022-02-03T19:21:33.123142Z"
    },
    "papermill": {
     "duration": 9.642768,
     "end_time": "2022-02-04T08:49:01.697980",
     "exception": false,
     "start_time": "2022-02-04T08:48:52.055212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q efficientnet >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f74cdd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:01.742364Z",
     "iopub.status.busy": "2022-02-04T08:49:01.741683Z",
     "iopub.status.idle": "2022-02-04T08:49:07.618766Z",
     "shell.execute_reply": "2022-02-04T08:49:07.618203Z",
     "shell.execute_reply.started": "2022-02-03T19:21:43.472456Z"
    },
    "papermill": {
     "duration": 5.902392,
     "end_time": "2022-02-04T08:49:07.618915",
     "exception": false,
     "start_time": "2022-02-04T08:49:01.716523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 08:49:02.337037: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-02-04 08:49:02.337156: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow as tf, re, math\n",
    "import tensorflow.keras.backend as K\n",
    "import efficientnet.tfkeras as efn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d32a20",
   "metadata": {
    "papermill": {
     "duration": 0.018519,
     "end_time": "2022-02-04T08:49:07.655531",
     "exception": false,
     "start_time": "2022-02-04T08:49:07.637012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration\n",
    "In order to be a proper cross validation with a meaningful overall CV score (aligned with LB score), **you need to choose the same** `IMG_SIZES`, `INC2019`, `INC2018`, and `EFF_NETS` **for each fold**. If your goal is to just run lots of experiments, then you can choose to have a different experiment in each fold. Then each fold is like a holdout validation experiment. When you find a configuration you like, you can use that configuration for all folds. \n",
    "* DEVICE - is GPU or TPU\n",
    "* SEED - a different seed produces a different triple stratified kfold split.\n",
    "* FOLDS - number of folds. Best set to 3, 5, or 15 but can be any number between 2 and 15\n",
    "* IMG_SIZES - is a Python list of length FOLDS. These are the image sizes to use each fold\n",
    "* INC2019 - This includes the new half of the 2019 competition data. The second half of the 2019 data is the comp data from 2018 plus 2017\n",
    "* INC2018 - This includes the second half of the 2019 competition data which is the comp data from 2018 plus 2017\n",
    "* BATCH_SIZES - is a list of length FOLDS. These are batch sizes for each fold. For maximum speed, it is best to use the largest batch size your GPU or TPU allows.\n",
    "* EPOCHS - is a list of length FOLDS. These are maximum epochs. Note that each fold, the best epoch model is saved and used. So if epochs is too large, it won't matter.\n",
    "* EFF_NETS - is a list of length FOLDS. These are the EfficientNets to use each fold. The number refers to the B. So a number of `0` refers to EfficientNetB0, and `1` refers to EfficientNetB1, etc.\n",
    "* WGTS - this should be `1/FOLDS` for each fold. This is the weight when ensembling the folds to predict the test set. If you want a weird ensemble, you can use different weights.\n",
    "* TTA - test time augmentation. Each test image is randomly augmented and predicted TTA times and the average prediction is used. TTA is also applied to OOF during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "befaf957",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:07.700713Z",
     "iopub.status.busy": "2022-02-04T08:49:07.699752Z",
     "iopub.status.idle": "2022-02-04T08:49:07.702756Z",
     "shell.execute_reply": "2022-02-04T08:49:07.702144Z",
     "shell.execute_reply.started": "2022-02-03T19:21:50.692155Z"
    },
    "papermill": {
     "duration": 0.028945,
     "end_time": "2022-02-04T08:49:07.702893",
     "exception": false,
     "start_time": "2022-02-04T08:49:07.673948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"TPU\" #or \"GPU\"\n",
    "\n",
    "# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD\n",
    "SEED = 42\n",
    "\n",
    "# NUMBER OF FOLDS. USE 3, 5, OR 15 \n",
    "FOLDS = 5\n",
    "\n",
    "# WHICH IMAGE SIZES TO LOAD EACH FOLD\n",
    "# CHOOSE 128, 192, 256, 384, 512, 768 \n",
    "IMG_SIZES = [384,384,384,384,384]\n",
    "\n",
    "# INCLUDE OLD COMP DATA? YES=1 NO=0\n",
    "INC2019 = [0,0,0,0,0]\n",
    "INC2018 = [1,1,1,1,1]\n",
    "\n",
    "# BATCH SIZE AND EPOCHS\n",
    "BATCH_SIZES = [32]*FOLDS\n",
    "EPOCHS = [12]*FOLDS\n",
    "\n",
    "# WHICH EFFICIENTNET B? TO USE\n",
    "EFF_NETS = [6,6,6,6,6]\n",
    "\n",
    "# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST\n",
    "WGTS = [1/FOLDS]*FOLDS\n",
    "\n",
    "# TEST TIME AUGMENTATION STEPS\n",
    "TTA = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62450bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:07.756778Z",
     "iopub.status.busy": "2022-02-04T08:49:07.755983Z",
     "iopub.status.idle": "2022-02-04T08:49:13.210295Z",
     "shell.execute_reply": "2022-02-04T08:49:13.210756Z",
     "shell.execute_reply.started": "2022-02-03T19:21:50.702128Z"
    },
    "papermill": {
     "duration": 5.489897,
     "end_time": "2022-02-04T08:49:13.210924",
     "exception": false,
     "start_time": "2022-02-04T08:49:07.721027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to TPU...\n",
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "initializing  TPU ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 08:49:07.750888: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-04 08:49:07.754238: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-02-04 08:49:07.754278: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-04 08:49:07.754306: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bb4740d88603): /proc/driver/nvidia/version does not exist\n",
      "2022-02-04 08:49:07.758059: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-04 08:49:07.759618: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-04 08:49:07.790139: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-02-04 08:49:07.790187: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n",
      "2022-02-04 08:49:07.812997: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-02-04 08:49:07.813047: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n",
      "2022-02-04 08:49:07.815423: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU initialized\n",
      "REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        DEVICE = \"GPU\"\n",
    "\n",
    "if DEVICE != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and single GPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if DEVICE == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db75267",
   "metadata": {
    "papermill": {
     "duration": 0.019855,
     "end_time": "2022-02-04T08:49:13.249946",
     "exception": false,
     "start_time": "2022-02-04T08:49:13.230091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1: Preprocess\n",
    "Preprocess has already been done and saved to TFRecords. Here we choose which size to load. We can use either 128x128, 192x192, 256x256, 384x384, 512x512, 768x768 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e53b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:13.291047Z",
     "iopub.status.busy": "2022-02-04T08:49:13.290413Z",
     "iopub.status.idle": "2022-02-04T08:49:17.524894Z",
     "shell.execute_reply": "2022-02-04T08:49:17.524287Z",
     "shell.execute_reply.started": "2022-02-03T19:21:56.263178Z"
    },
    "papermill": {
     "duration": 4.256432,
     "end_time": "2022-02-04T08:49:17.525031",
     "exception": false,
     "start_time": "2022-02-04T08:49:13.268599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://kds-a764cdbc2203a21cb29fd5996244b699cc6aa8996dd5558576eda051', 'gs://kds-a764cdbc2203a21cb29fd5996244b699cc6aa8996dd5558576eda051', 'gs://kds-a764cdbc2203a21cb29fd5996244b699cc6aa8996dd5558576eda051', 'gs://kds-a764cdbc2203a21cb29fd5996244b699cc6aa8996dd5558576eda051', 'gs://kds-a764cdbc2203a21cb29fd5996244b699cc6aa8996dd5558576eda051']\n",
      "['gs://kds-cd04fabfa74305241c3cdd5296e75d6fc3b87605cfbf8694d9715641', 'gs://kds-cd04fabfa74305241c3cdd5296e75d6fc3b87605cfbf8694d9715641', 'gs://kds-cd04fabfa74305241c3cdd5296e75d6fc3b87605cfbf8694d9715641', 'gs://kds-cd04fabfa74305241c3cdd5296e75d6fc3b87605cfbf8694d9715641', 'gs://kds-cd04fabfa74305241c3cdd5296e75d6fc3b87605cfbf8694d9715641']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 08:49:17.368934: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:17.452346: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    }
   ],
   "source": [
    "GCS_PATH = [None]*FOLDS; GCS_PATH2 = [None]*FOLDS\n",
    "for i,k in enumerate(IMG_SIZES):\n",
    "    GCS_PATH[i] = KaggleDatasets().get_gcs_path('melanoma-%ix%i'%(k,k))\n",
    "    GCS_PATH2[i] = KaggleDatasets().get_gcs_path('isic2019-%ix%i'%(k,k))\n",
    "print(GCS_PATH)\n",
    "print(GCS_PATH2)\n",
    "files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))\n",
    "files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a91c21",
   "metadata": {
    "papermill": {
     "duration": 0.019519,
     "end_time": "2022-02-04T08:49:17.564280",
     "exception": false,
     "start_time": "2022-02-04T08:49:17.544761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2: Data Augmentation\n",
    "This notebook uses rotation, sheer, zoom, shift augmentation first shown in this notebook [here][1] and successfully used in Melanoma comp by AgentAuers [here][2]. This notebook also uses horizontal flip, hue, saturation, contrast, brightness augmentation similar to last years winner and also similar to AgentAuers' notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282c8bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:17.607036Z",
     "iopub.status.busy": "2022-02-04T08:49:17.606442Z",
     "iopub.status.idle": "2022-02-04T08:49:17.609895Z",
     "shell.execute_reply": "2022-02-04T08:49:17.610480Z",
     "shell.execute_reply.started": "2022-02-03T19:22:00.162684Z"
    },
    "papermill": {
     "duration": 0.026481,
     "end_time": "2022-02-04T08:49:17.610642",
     "exception": false,
     "start_time": "2022-02-04T08:49:17.584161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROT_ = 180.0\n",
    "SHR_ = 2.0\n",
    "HZOOM_ = 8.0\n",
    "WZOOM_ = 8.0\n",
    "HSHIFT_ = 8.0\n",
    "WSHIFT_ = 8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61e1766f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:17.653332Z",
     "iopub.status.busy": "2022-02-04T08:49:17.652652Z",
     "iopub.status.idle": "2022-02-04T08:49:17.671130Z",
     "shell.execute_reply": "2022-02-04T08:49:17.671698Z",
     "shell.execute_reply.started": "2022-02-03T19:22:00.168778Z"
    },
    "papermill": {
     "duration": 0.041408,
     "end_time": "2022-02-04T08:49:17.671868",
     "exception": false,
     "start_time": "2022-02-04T08:49:17.630460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)    \n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, DIM=256):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = ROT_ * tf.random.normal([1], dtype='float32')\n",
    "    shr = SHR_ * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n",
    "    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "\n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM, DIM,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fde63a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:17.726734Z",
     "iopub.status.busy": "2022-02-04T08:49:17.726029Z",
     "iopub.status.idle": "2022-02-04T08:49:17.727978Z",
     "shell.execute_reply": "2022-02-04T08:49:17.728487Z",
     "shell.execute_reply.started": "2022-02-03T19:22:00.191041Z"
    },
    "papermill": {
     "duration": 0.036869,
     "end_time": "2022-02-04T08:49:17.728656",
     "exception": false,
     "start_time": "2022-02-04T08:49:17.691787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }           \n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['target']\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_name):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['image_name'] if return_image_name else 0\n",
    "\n",
    " \n",
    "def prepare_image(img, augment=True, dim=256):    \n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    if augment:\n",
    "        img = transform(img,DIM=dim)\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        #img = tf.image.random_hue(img, 0.01)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "                      \n",
    "    img = tf.reshape(img, [dim,dim, 3])\n",
    "            \n",
    "    return img\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n",
    "         for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9feb7ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:17.778225Z",
     "iopub.status.busy": "2022-02-04T08:49:17.771010Z",
     "iopub.status.idle": "2022-02-04T08:49:17.781554Z",
     "shell.execute_reply": "2022-02-04T08:49:17.782159Z",
     "shell.execute_reply.started": "2022-02-03T19:22:00.210383Z"
    },
    "papermill": {
     "duration": 0.033658,
     "end_time": "2022-02-04T08:49:17.782338",
     "exception": false,
     "start_time": "2022-02-04T08:49:17.748680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(files, augment = False, shuffle = False, repeat = False, \n",
    "                labeled=True, return_image_names=True, batch_size=16, dim=256):\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    \n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(1024*8)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "        \n",
    "    if labeled: \n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n",
    "                    num_parallel_calls=AUTO)      \n",
    "    \n",
    "    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, dim=dim), \n",
    "                                               imgname_or_label), \n",
    "                num_parallel_calls=AUTO)\n",
    "    \n",
    "    ds = ds.batch(batch_size * REPLICAS)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6802261",
   "metadata": {
    "papermill": {
     "duration": 0.019838,
     "end_time": "2022-02-04T08:49:17.822519",
     "exception": false,
     "start_time": "2022-02-04T08:49:17.802681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 3: Build Models\n",
    "change backbones, custom heads, losses, and optimizers. Also consider inputing meta features into your CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d64ae601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:17.867833Z",
     "iopub.status.busy": "2022-02-04T08:49:17.866763Z",
     "iopub.status.idle": "2022-02-04T08:49:18.096789Z",
     "shell.execute_reply": "2022-02-04T08:49:18.096154Z",
     "shell.execute_reply.started": "2022-02-03T19:22:00.228448Z"
    },
    "papermill": {
     "duration": 0.254336,
     "end_time": "2022-02-04T08:49:18.096932",
     "exception": false,
     "start_time": "2022-02-04T08:49:17.842596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def build_model_efn(dim=128, ef=0):\n",
    "    EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n",
    "        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6]\n",
    "    inp = tf.keras.layers.Input(shape=(dim,dim,3))\n",
    "    base = EFNS[ef](input_shape=(dim,dim,3),weights='imagenet',include_top=False)\n",
    "    x = base(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    model = model = tf.keras.Model(inputs=inp,outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) \n",
    "    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "   \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "   \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])# SKIP Connection\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "   \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def ResNet50(input_shape=(224, 224, 3)):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
    "    \n",
    "    base_model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    \n",
    "    headModel = base_model.output\n",
    "    headModel = Flatten()(headModel)\n",
    "    headModel=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
    "    headModel=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
    "    headModel = Dense( 1,activation='sigmoid', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
    "    model = Model(inputs=base_model.input, outputs=headModel)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) \n",
    "    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_InceptionV3(input_tensor=Input(shape=(224, 224, 3))):\n",
    "    base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) \n",
    "    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_Xception(input_tensor=Input(shape=(224, 224, 3))):\n",
    "    base_model = tf.keras.applications.Xception(input_tensor=input_tensor,weights='imagenet',include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) \n",
    "    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "def build_DenseNet201(input_tensor=Input(shape=(224, 224, 3))):\n",
    "    base_model = tf.keras.applications.DenseNet201(input_tensor=input_tensor,weights='imagenet',include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) \n",
    "    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde45d3",
   "metadata": {
    "papermill": {
     "duration": 0.019634,
     "end_time": "2022-02-04T08:49:18.136741",
     "exception": false,
     "start_time": "2022-02-04T08:49:18.117107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 4: Train Schedule\n",
    "This is a common train schedule for transfer learning. The learning rate starts near zero, then increases to a maximum, then decays over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cef49b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:18.185203Z",
     "iopub.status.busy": "2022-02-04T08:49:18.184329Z",
     "iopub.status.idle": "2022-02-04T08:49:18.187089Z",
     "shell.execute_reply": "2022-02-04T08:49:18.186587Z",
     "shell.execute_reply.started": "2022-02-03T19:22:00.296637Z"
    },
    "papermill": {
     "duration": 0.03032,
     "end_time": "2022-02-04T08:49:18.187249",
     "exception": false,
     "start_time": "2022-02-04T08:49:18.156929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size=8):\n",
    "    lr_start   = 0.000005\n",
    "    lr_max     = 0.00000125 * REPLICAS * batch_size\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "            \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190806d",
   "metadata": {
    "papermill": {
     "duration": 0.019991,
     "end_time": "2022-02-04T08:49:18.227780",
     "exception": false,
     "start_time": "2022-02-04T08:49:18.207789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Late Fushion Model\n",
    "The model will be trained for the number of FOLDS and EPOCHS you chose in the configuration above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e25065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T08:49:18.272026Z",
     "iopub.status.busy": "2022-02-04T08:49:18.270948Z",
     "iopub.status.idle": "2022-02-04T15:57:39.550838Z",
     "shell.execute_reply": "2022-02-04T15:57:39.551319Z",
     "shell.execute_reply.started": "2022-02-03T19:22:00.307867Z"
    },
    "papermill": {
     "duration": 25701.303781,
     "end_time": "2022-02-04T15:57:39.551641",
     "exception": false,
     "start_time": "2022-02-04T08:49:18.247860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "#### FOLD 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 08:49:26.572591: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:26.641030: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:26.712123: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:26.784290: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:26.855432: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:26.930239: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:26.998739: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.066896: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.131160: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.207810: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.280970: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.350930: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.424508: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.545221: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.609946: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.687391: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.756467: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.826918: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.894810: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:27.962786: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:28.110391: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:28.176385: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:28.241111: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:28.307362: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Using 2018+2017 external data\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 08:49:28.371957: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:28.437044: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:28.506721: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 08:49:28.570600: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b6_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "165527552/165527152 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 0s 0us/step\n",
      "Training...\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 292s 1s/step - loss: 0.6745 - auc: 0.5667 - val_loss: 0.4797 - val_auc: 0.4659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 08:55:52.510962: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 171226, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643964952.507422547\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 171226, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 120s 842ms/step - loss: 0.2770 - auc: 0.7230 - val_loss: 0.1684 - val_auc: 0.8465\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 120s 842ms/step - loss: 0.2334 - auc: 0.8781 - val_loss: 0.1666 - val_auc: 0.8574\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 120s 842ms/step - loss: 0.2234 - auc: 0.9010 - val_loss: 0.1647 - val_auc: 0.8980\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 119s 840ms/step - loss: 0.2176 - auc: 0.9167 - val_loss: 0.1663 - val_auc: 0.8830\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 119s 842ms/step - loss: 0.2110 - auc: 0.9280 - val_loss: 0.1701 - val_auc: 0.8709\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 120s 842ms/step - loss: 0.2012 - auc: 0.9378 - val_loss: 0.1657 - val_auc: 0.8870\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 0.1971 - auc: 0.9492 - val_loss: 0.1616 - val_auc: 0.8966\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.1863 - auc: 0.9580 - val_loss: 0.1675 - val_auc: 0.8991\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 120s 845ms/step - loss: 0.1809 - auc: 0.9621 - val_loss: 0.1633 - val_auc: 0.9050\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.1769 - auc: 0.9707 - val_loss: 0.1610 - val_auc: 0.9034\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 120s 842ms/step - loss: 0.1741 - auc: 0.9746 - val_loss: 0.1637 - val_auc: 0.9004\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 146s 539ms/step - loss: 0.3923 - auc: 0.6469 - val_loss: 0.1743 - val_auc: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 09:20:46.057169: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 257203, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643966446.056264805\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 257203, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 59s 416ms/step - loss: 0.2379 - auc: 0.8535 - val_loss: 0.1752 - val_auc: 0.7965\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 59s 416ms/step - loss: 0.2248 - auc: 0.8912 - val_loss: 0.1693 - val_auc: 0.8541\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2216 - auc: 0.8985 - val_loss: 0.2053 - val_auc: 0.8429\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2162 - auc: 0.9087 - val_loss: 0.1681 - val_auc: 0.8371\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 59s 417ms/step - loss: 0.2191 - auc: 0.9111 - val_loss: 0.1702 - val_auc: 0.7414\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2115 - auc: 0.9221 - val_loss: 0.1690 - val_auc: 0.8549\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2051 - auc: 0.9319 - val_loss: 0.1642 - val_auc: 0.8529\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 59s 417ms/step - loss: 0.1952 - auc: 0.9491 - val_loss: 0.1674 - val_auc: 0.8700\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 59s 416ms/step - loss: 0.1933 - auc: 0.9536 - val_loss: 0.1723 - val_auc: 0.8673\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 59s 417ms/step - loss: 0.1845 - auc: 0.9613 - val_loss: 0.1667 - val_auc: 0.8756\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 59s 417ms/step - loss: 0.1756 - auc: 0.9679 - val_loss: 0.1694 - val_auc: 0.8708\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 118s 523ms/step - loss: 0.4819 - auc: 0.5873 - val_loss: 0.1778 - val_auc: 0.5922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 09:33:49.246868: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 305724, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643967229.246687981\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 305724, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 63s 443ms/step - loss: 0.2412 - auc: 0.8569 - val_loss: 0.1717 - val_auc: 0.7977\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2272 - auc: 0.8927 - val_loss: 0.1712 - val_auc: 0.8271\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 64s 452ms/step - loss: 0.2189 - auc: 0.9081 - val_loss: 0.1809 - val_auc: 0.8432\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 63s 443ms/step - loss: 0.2146 - auc: 0.9115 - val_loss: 0.1840 - val_auc: 0.8409\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2138 - auc: 0.9233 - val_loss: 0.1755 - val_auc: 0.8326\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 63s 443ms/step - loss: 0.2040 - auc: 0.9359 - val_loss: 0.1688 - val_auc: 0.8609\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 63s 442ms/step - loss: 0.1938 - auc: 0.9539 - val_loss: 0.1693 - val_auc: 0.8652\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 63s 443ms/step - loss: 0.1880 - auc: 0.9608 - val_loss: 0.1645 - val_auc: 0.8728\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1795 - auc: 0.9687 - val_loss: 0.1649 - val_auc: 0.8957\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 63s 443ms/step - loss: 0.1695 - auc: 0.9766 - val_loss: 0.1816 - val_auc: 0.8943\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1644 - auc: 0.9812 - val_loss: 0.1690 - val_auc: 0.8645\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 281s 858ms/step - loss: 0.3829 - auc: 0.6888 - val_loss: 0.2106 - val_auc: 0.4962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 09:50:13.791280: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 363899, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643968213.791200103\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 363899, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 92s 645ms/step - loss: 0.2364 - auc: 0.8710 - val_loss: 0.1774 - val_auc: 0.6903\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 91s 644ms/step - loss: 0.2241 - auc: 0.9005 - val_loss: 0.1720 - val_auc: 0.7503\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 91s 643ms/step - loss: 0.2186 - auc: 0.9052 - val_loss: 0.1724 - val_auc: 0.7320\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 91s 643ms/step - loss: 0.2188 - auc: 0.9106 - val_loss: 0.1696 - val_auc: 0.8117\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 91s 643ms/step - loss: 0.2213 - auc: 0.9045 - val_loss: 0.1684 - val_auc: 0.8402\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 91s 644ms/step - loss: 0.2097 - auc: 0.9264 - val_loss: 0.1994 - val_auc: 0.7233\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 91s 642ms/step - loss: 0.2017 - auc: 0.9388 - val_loss: 0.1741 - val_auc: 0.8221\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 91s 642ms/step - loss: 0.1952 - auc: 0.9495 - val_loss: 0.1894 - val_auc: 0.7001\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 91s 643ms/step - loss: 0.1879 - auc: 0.9639 - val_loss: 0.1777 - val_auc: 0.8870\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 91s 644ms/step - loss: 0.1819 - auc: 0.9682 - val_loss: 0.1632 - val_auc: 0.8593\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 92s 645ms/step - loss: 0.1747 - auc: 0.9740 - val_loss: 0.1785 - val_auc: 0.8531\n",
      "Predicting OOF with TTA...\n",
      "70/70 [==============================] - 99s 1s/step\n",
      "70/70 [==============================] - 82s 1s/step\n",
      "70/70 [==============================] - 75s 1s/step\n",
      "70/70 [==============================] - 112s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 10:13:58.740316: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 469288, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643969638.740222330\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 469288, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### VAL AVERAGE FUSION FOLD 1 OOF AUC with TTA = 0.928\n",
      "#### VAL WEIGHTED AVERAGE FOLD 1 OOF AUC with TTA = 0.932\n",
      "#########################\n",
      "#### FOLD 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 10:14:17.529443: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:17.608933: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:17.683593: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:17.753560: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:17.833047: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:17.910620: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:17.988020: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.060171: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.131481: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.222455: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.300836: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.371722: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.450131: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.526419: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.606751: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.682981: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.761312: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.842456: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:18.921882: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:19.001405: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:19.078082: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:19.154715: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:19.231842: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:19.298469: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Using 2018+2017 external data\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 10:14:19.370693: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:19.449848: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:19.527037: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 10:14:19.602884: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 293s 1s/step - loss: 0.6344 - auc: 0.5355 - val_loss: 0.5294 - val_auc: 0.6444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 10:20:26.500090: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 653609, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643970026.499977665\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 653609, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 119s 840ms/step - loss: 0.2879 - auc: 0.7229 - val_loss: 0.1721 - val_auc: 0.8072\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 119s 839ms/step - loss: 0.2286 - auc: 0.8773 - val_loss: 0.1703 - val_auc: 0.8501\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 119s 840ms/step - loss: 0.2173 - auc: 0.9040 - val_loss: 0.1803 - val_auc: 0.8347\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 119s 838ms/step - loss: 0.2145 - auc: 0.9108 - val_loss: 0.1804 - val_auc: 0.8503\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 119s 839ms/step - loss: 0.2122 - auc: 0.9246 - val_loss: 0.1645 - val_auc: 0.8811\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 119s 840ms/step - loss: 0.2017 - auc: 0.9362 - val_loss: 0.1738 - val_auc: 0.8746\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 120s 842ms/step - loss: 0.1939 - auc: 0.9462 - val_loss: 0.1646 - val_auc: 0.8884\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 119s 841ms/step - loss: 0.1875 - auc: 0.9554 - val_loss: 0.1637 - val_auc: 0.8768\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 0.1791 - auc: 0.9636 - val_loss: 0.1681 - val_auc: 0.8666\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.1733 - auc: 0.9701 - val_loss: 0.1679 - val_auc: 0.8756\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 0.1713 - auc: 0.9756 - val_loss: 0.1673 - val_auc: 0.8701\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 156s 551ms/step - loss: 0.3339 - auc: 0.6288 - val_loss: 0.1742 - val_auc: 0.7078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 10:45:22.265865: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 750338, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643971522.265664996\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 750338, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 60s 419ms/step - loss: 0.2337 - auc: 0.8598 - val_loss: 0.1880 - val_auc: 0.8090\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2207 - auc: 0.8919 - val_loss: 0.1777 - val_auc: 0.7792\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 59s 419ms/step - loss: 0.2198 - auc: 0.9026 - val_loss: 0.1714 - val_auc: 0.8308\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2166 - auc: 0.9092 - val_loss: 0.1840 - val_auc: 0.7624\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2084 - auc: 0.9210 - val_loss: 0.1736 - val_auc: 0.8464\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2090 - auc: 0.9264 - val_loss: 0.1710 - val_auc: 0.8837\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 59s 417ms/step - loss: 0.1994 - auc: 0.9361 - val_loss: 0.1680 - val_auc: 0.8775\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.1931 - auc: 0.9476 - val_loss: 0.1690 - val_auc: 0.8603\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 60s 419ms/step - loss: 0.1888 - auc: 0.9533 - val_loss: 0.1683 - val_auc: 0.8966\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 60s 420ms/step - loss: 0.1834 - auc: 0.9640 - val_loss: 0.1680 - val_auc: 0.8349\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 60s 421ms/step - loss: 0.1790 - auc: 0.9664 - val_loss: 0.1681 - val_auc: 0.8903\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 121s 534ms/step - loss: 0.4533 - auc: 0.5823 - val_loss: 0.1793 - val_auc: 0.5655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 10:58:34.346906: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 801883, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643972314.346139933\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 801883, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.2410 - auc: 0.8597 - val_loss: 0.1705 - val_auc: 0.8225\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 63s 447ms/step - loss: 0.2215 - auc: 0.8906 - val_loss: 0.1724 - val_auc: 0.8183\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 63s 446ms/step - loss: 0.2150 - auc: 0.9156 - val_loss: 0.1706 - val_auc: 0.8184\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2034 - auc: 0.9254 - val_loss: 0.1973 - val_auc: 0.8275\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2048 - auc: 0.9270 - val_loss: 0.1762 - val_auc: 0.8555\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.1976 - auc: 0.9451 - val_loss: 0.1871 - val_auc: 0.7613\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1919 - auc: 0.9471 - val_loss: 0.1685 - val_auc: 0.8775\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.1818 - auc: 0.9664 - val_loss: 0.1737 - val_auc: 0.8250\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.1765 - auc: 0.9674 - val_loss: 0.1743 - val_auc: 0.8397\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.1683 - auc: 0.9791 - val_loss: 0.1673 - val_auc: 0.8249\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1614 - auc: 0.9853 - val_loss: 0.1696 - val_auc: 0.8301\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 296s 872ms/step - loss: 0.4764 - auc: 0.6000 - val_loss: 0.2036 - val_auc: 0.5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 11:15:14.528931: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 869250, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643973314.528825303\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 869250, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.2315 - auc: 0.8712 - val_loss: 0.1886 - val_auc: 0.6307\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 0.2248 - auc: 0.8964 - val_loss: 0.1729 - val_auc: 0.8102\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.2162 - auc: 0.9060 - val_loss: 0.2087 - val_auc: 0.7372\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 92s 647ms/step - loss: 0.2116 - auc: 0.9179 - val_loss: 0.1750 - val_auc: 0.7515\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 92s 648ms/step - loss: 0.2083 - auc: 0.9209 - val_loss: 0.1742 - val_auc: 0.7950\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 92s 648ms/step - loss: 0.2032 - auc: 0.9310 - val_loss: 0.1687 - val_auc: 0.7778\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 0.1971 - auc: 0.9454 - val_loss: 0.1705 - val_auc: 0.8552\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 92s 648ms/step - loss: 0.1891 - auc: 0.9572 - val_loss: 0.1662 - val_auc: 0.8799\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 92s 651ms/step - loss: 0.1827 - auc: 0.9673 - val_loss: 0.1687 - val_auc: 0.7536\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.1778 - auc: 0.9658 - val_loss: 0.1654 - val_auc: 0.8318\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.1720 - auc: 0.9738 - val_loss: 0.1650 - val_auc: 0.8701\n",
      "Predicting OOF with TTA...\n",
      "70/70 [==============================] - 108s 1s/step\n",
      "70/70 [==============================] - 80s 1s/step\n",
      "70/70 [==============================] - 76s 1s/step\n",
      "70/70 [==============================] - 112s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 11:39:27.199041: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 999763, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643974767.198879189\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 999763, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### VAL AVERAGE FUSION FOLD 2 OOF AUC with TTA = 0.908\n",
      "#### VAL WEIGHTED AVERAGE FOLD 2 OOF AUC with TTA = 0.900\n",
      "#########################\n",
      "#### FOLD 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 11:39:45.637453: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:45.721118: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:45.806931: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:45.882416: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:45.966001: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.052349: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.132160: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.202141: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.273192: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.348974: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.421232: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.498962: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.575091: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.738335: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.811662: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.887405: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:46.960009: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.035910: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.122228: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.192577: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.264900: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.332037: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.400666: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.469568: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.546495: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.620120: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Using 2018+2017 external data\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 11:39:47.693643: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 11:39:47.782628: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 291s 943ms/step - loss: 0.6611 - auc: 0.5193 - val_loss: 0.5291 - val_auc: 0.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 11:45:59.314128: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1184080, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643975159.313779053\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1184080, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 120s 847ms/step - loss: 0.2748 - auc: 0.7127 - val_loss: 0.1673 - val_auc: 0.8640\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.2293 - auc: 0.8759 - val_loss: 0.1677 - val_auc: 0.8930\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 0.2216 - auc: 0.8968 - val_loss: 0.1636 - val_auc: 0.8953\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.2147 - auc: 0.9156 - val_loss: 0.1609 - val_auc: 0.8978\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 120s 845ms/step - loss: 0.2122 - auc: 0.9175 - val_loss: 0.1610 - val_auc: 0.9114\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 0.2021 - auc: 0.9400 - val_loss: 0.1649 - val_auc: 0.8981\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 120s 845ms/step - loss: 0.1948 - auc: 0.9469 - val_loss: 0.1628 - val_auc: 0.9133\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.1878 - auc: 0.9559 - val_loss: 0.1614 - val_auc: 0.9099\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 120s 842ms/step - loss: 0.1798 - auc: 0.9643 - val_loss: 0.1572 - val_auc: 0.9041\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 0.1773 - auc: 0.9711 - val_loss: 0.1581 - val_auc: 0.9119\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 120s 842ms/step - loss: 0.1712 - auc: 0.9757 - val_loss: 0.1588 - val_auc: 0.8984\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 150s 495ms/step - loss: 0.4472 - auc: 0.6177 - val_loss: 0.1726 - val_auc: 0.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 12:10:57.345799: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1280809, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643976657.345681452\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1280809, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 59s 419ms/step - loss: 0.2340 - auc: 0.8561 - val_loss: 0.1679 - val_auc: 0.8635\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 59s 417ms/step - loss: 0.2256 - auc: 0.8893 - val_loss: 0.1687 - val_auc: 0.8246\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2173 - auc: 0.9073 - val_loss: 0.1666 - val_auc: 0.8304\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 59s 419ms/step - loss: 0.2168 - auc: 0.9071 - val_loss: 0.1673 - val_auc: 0.8289\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 59s 419ms/step - loss: 0.2133 - auc: 0.9096 - val_loss: 0.1644 - val_auc: 0.8650\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 59s 419ms/step - loss: 0.2075 - auc: 0.9226 - val_loss: 0.1682 - val_auc: 0.8238\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 0.2037 - auc: 0.9264 - val_loss: 0.1692 - val_auc: 0.7439\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 60s 419ms/step - loss: 0.1962 - auc: 0.9462 - val_loss: 0.1636 - val_auc: 0.8566\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 60s 420ms/step - loss: 0.1911 - auc: 0.9544 - val_loss: 0.1728 - val_auc: 0.8859\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 59s 419ms/step - loss: 0.1837 - auc: 0.9602 - val_loss: 0.1666 - val_auc: 0.9162\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 60s 419ms/step - loss: 0.1782 - auc: 0.9678 - val_loss: 0.1621 - val_auc: 0.8902\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 116s 494ms/step - loss: 0.4871 - auc: 0.5953 - val_loss: 0.1782 - val_auc: 0.5842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 12:24:06.573789: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1335378, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643977446.573550614\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1335378, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2393 - auc: 0.8540 - val_loss: 0.1666 - val_auc: 0.8405\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2216 - auc: 0.8927 - val_loss: 0.1674 - val_auc: 0.8674\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 63s 443ms/step - loss: 0.2140 - auc: 0.9124 - val_loss: 0.1644 - val_auc: 0.8744\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2127 - auc: 0.9150 - val_loss: 0.1640 - val_auc: 0.8949\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.2087 - auc: 0.9175 - val_loss: 0.1650 - val_auc: 0.9012\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.1966 - auc: 0.9432 - val_loss: 0.1628 - val_auc: 0.8817\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1940 - auc: 0.9492 - val_loss: 0.1630 - val_auc: 0.8713\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1823 - auc: 0.9638 - val_loss: 0.1644 - val_auc: 0.8560\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.1819 - auc: 0.9700 - val_loss: 0.1667 - val_auc: 0.8662\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1693 - auc: 0.9786 - val_loss: 0.1643 - val_auc: 0.8396\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1662 - auc: 0.9793 - val_loss: 0.1656 - val_auc: 0.8460\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 280s 785ms/step - loss: 0.3650 - auc: 0.6536 - val_loss: 0.2088 - val_auc: 0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 12:40:31.185000: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1404337, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643978431.184431572\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1404337, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.2253 - auc: 0.8801 - val_loss: 0.1690 - val_auc: 0.8497\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 0.2219 - auc: 0.8972 - val_loss: 0.2066 - val_auc: 0.8287\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 92s 648ms/step - loss: 0.2172 - auc: 0.9011 - val_loss: 0.1653 - val_auc: 0.8652\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 95s 671ms/step - loss: 0.2173 - auc: 0.9045 - val_loss: 0.1748 - val_auc: 0.8429\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 0.2141 - auc: 0.9101 - val_loss: 0.1635 - val_auc: 0.8761\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.2053 - auc: 0.9316 - val_loss: 0.1693 - val_auc: 0.7481\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 92s 648ms/step - loss: 0.1963 - auc: 0.9424 - val_loss: 0.1612 - val_auc: 0.8828\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 0.1933 - auc: 0.9501 - val_loss: 0.1627 - val_auc: 0.8761\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 92s 648ms/step - loss: 0.1853 - auc: 0.9640 - val_loss: 0.1655 - val_auc: 0.8690\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 92s 648ms/step - loss: 0.1809 - auc: 0.9688 - val_loss: 0.1624 - val_auc: 0.8641\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 92s 648ms/step - loss: 0.1721 - auc: 0.9762 - val_loss: 0.1620 - val_auc: 0.8570\n",
      "Predicting OOF with TTA...\n",
      "70/70 [==============================] - 99s 1s/step\n",
      "70/70 [==============================] - 79s 1s/step\n",
      "70/70 [==============================] - 76s 1s/step\n",
      "70/70 [==============================] - 111s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 13:04:22.252700: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1502510, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643979862.252425369\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1502510, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### VAL AVERAGE FUSION FOLD 3 OOF AUC with TTA = 0.948\n",
      "#### VAL WEIGHTED AVERAGE FOLD 3 OOF AUC with TTA = 0.949\n",
      "#########################\n",
      "#### FOLD 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 13:04:40.823496: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:40.900455: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:40.991897: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.066297: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.137319: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.229429: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.301569: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.384858: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.455677: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.532827: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.610075: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.683671: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.782216: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.898832: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:41.970546: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.042255: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.106049: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.175834: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.246121: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.313345: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.384571: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.457462: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.531218: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.601272: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Using 2018+2017 external data\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 13:04:42.675739: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.745127: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.836908: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 13:04:42.919108: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 298s 943ms/step - loss: 0.6256 - auc: 0.5163 - val_loss: 0.4306 - val_auc: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 13:10:57.974237: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1704740, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643980257.973914022\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1704740, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.2723 - auc: 0.7225 - val_loss: 0.1683 - val_auc: 0.8346\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 120s 848ms/step - loss: 0.2250 - auc: 0.8704 - val_loss: 0.1652 - val_auc: 0.8565\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 121s 850ms/step - loss: 0.2102 - auc: 0.9019 - val_loss: 0.1687 - val_auc: 0.8891\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 121s 849ms/step - loss: 0.2100 - auc: 0.9134 - val_loss: 0.1623 - val_auc: 0.8631\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 121s 849ms/step - loss: 0.2012 - auc: 0.9227 - val_loss: 0.1627 - val_auc: 0.8936\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 120s 848ms/step - loss: 0.1955 - auc: 0.9373 - val_loss: 0.1619 - val_auc: 0.8939\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 121s 850ms/step - loss: 0.1882 - auc: 0.9492 - val_loss: 0.1620 - val_auc: 0.8765\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 120s 848ms/step - loss: 0.1825 - auc: 0.9530 - val_loss: 0.1605 - val_auc: 0.8667\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 121s 850ms/step - loss: 0.1762 - auc: 0.9654 - val_loss: 0.1618 - val_auc: 0.9001\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 121s 851ms/step - loss: 0.1709 - auc: 0.9695 - val_loss: 0.1623 - val_auc: 0.8882\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 121s 849ms/step - loss: 0.1690 - auc: 0.9710 - val_loss: 0.1638 - val_auc: 0.8913\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 158s 504ms/step - loss: 0.3571 - auc: 0.6003 - val_loss: 0.1714 - val_auc: 0.7746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 13:36:18.327363: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1806985, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643981778.326555070\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1806985, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 60s 423ms/step - loss: 0.2268 - auc: 0.8496 - val_loss: 0.1665 - val_auc: 0.8632\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 60s 423ms/step - loss: 0.2170 - auc: 0.8779 - val_loss: 0.1696 - val_auc: 0.7710\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 60s 422ms/step - loss: 0.2109 - auc: 0.8931 - val_loss: 0.1701 - val_auc: 0.7995\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 60s 422ms/step - loss: 0.2059 - auc: 0.9147 - val_loss: 0.1711 - val_auc: 0.7357\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 60s 422ms/step - loss: 0.2032 - auc: 0.9109 - val_loss: 0.1710 - val_auc: 0.8628\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 60s 422ms/step - loss: 0.2022 - auc: 0.9160 - val_loss: 0.1677 - val_auc: 0.8397\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 60s 423ms/step - loss: 0.1962 - auc: 0.9336 - val_loss: 0.1714 - val_auc: 0.8759\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 60s 423ms/step - loss: 0.1919 - auc: 0.9469 - val_loss: 0.1709 - val_auc: 0.8092\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 60s 424ms/step - loss: 0.1863 - auc: 0.9505 - val_loss: 0.1628 - val_auc: 0.9011\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 60s 425ms/step - loss: 0.1815 - auc: 0.9576 - val_loss: 0.1641 - val_auc: 0.8749\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 60s 424ms/step - loss: 0.1737 - auc: 0.9674 - val_loss: 0.1650 - val_auc: 0.8952\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 120s 502ms/step - loss: 0.3934 - auc: 0.5834 - val_loss: 0.1786 - val_auc: 0.6205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 13:49:33.534904: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1852446, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643982573.534364907\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1852446, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 64s 450ms/step - loss: 0.2272 - auc: 0.8685 - val_loss: 0.1720 - val_auc: 0.8229\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 64s 449ms/step - loss: 0.2123 - auc: 0.9002 - val_loss: 0.1662 - val_auc: 0.8566\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 64s 450ms/step - loss: 0.2093 - auc: 0.9108 - val_loss: 0.1688 - val_auc: 0.8525\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 64s 450ms/step - loss: 0.2010 - auc: 0.9237 - val_loss: 0.1735 - val_auc: 0.7501\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 64s 450ms/step - loss: 0.2015 - auc: 0.9272 - val_loss: 0.1760 - val_auc: 0.8728\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 64s 450ms/step - loss: 0.1921 - auc: 0.9420 - val_loss: 0.1655 - val_auc: 0.8909\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 64s 449ms/step - loss: 0.1862 - auc: 0.9553 - val_loss: 0.1632 - val_auc: 0.8177\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 64s 450ms/step - loss: 0.1813 - auc: 0.9558 - val_loss: 0.1659 - val_auc: 0.8614\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 64s 449ms/step - loss: 0.1724 - auc: 0.9660 - val_loss: 0.1641 - val_auc: 0.8475\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 64s 450ms/step - loss: 0.1650 - auc: 0.9772 - val_loss: 0.1662 - val_auc: 0.8479\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 64s 449ms/step - loss: 0.1601 - auc: 0.9800 - val_loss: 0.1677 - val_auc: 0.8565\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 296s 800ms/step - loss: 0.3535 - auc: 0.6610 - val_loss: 0.2015 - val_auc: 0.6321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:06:24.921348: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 1921369, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643983584.920967717\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 1921369, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 93s 657ms/step - loss: 0.2189 - auc: 0.8759 - val_loss: 0.1730 - val_auc: 0.8122\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 93s 656ms/step - loss: 0.2142 - auc: 0.8964 - val_loss: 0.1728 - val_auc: 0.7737\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 93s 657ms/step - loss: 0.2120 - auc: 0.9018 - val_loss: 0.1709 - val_auc: 0.7752\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 93s 656ms/step - loss: 0.2094 - auc: 0.9094 - val_loss: 0.1695 - val_auc: 0.8227\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 93s 657ms/step - loss: 0.2074 - auc: 0.9131 - val_loss: 0.1704 - val_auc: 0.8182\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 93s 655ms/step - loss: 0.2022 - auc: 0.9225 - val_loss: 0.1660 - val_auc: 0.8554\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 93s 657ms/step - loss: 0.1929 - auc: 0.9422 - val_loss: 0.1652 - val_auc: 0.8253\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 93s 655ms/step - loss: 0.1898 - auc: 0.9502 - val_loss: 0.1637 - val_auc: 0.8539\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 93s 656ms/step - loss: 0.1809 - auc: 0.9593 - val_loss: 0.1643 - val_auc: 0.8557\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 93s 654ms/step - loss: 0.1729 - auc: 0.9707 - val_loss: 0.1648 - val_auc: 0.8348\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 93s 655ms/step - loss: 0.1694 - auc: 0.9741 - val_loss: 0.1660 - val_auc: 0.8006\n",
      "Predicting OOF with TTA...\n",
      "69/69 [==============================] - 99s 1s/step\n",
      "69/69 [==============================] - 79s 1s/step\n",
      "69/69 [==============================] - 76s 1s/step\n",
      "69/69 [==============================] - 111s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:30:57.553312: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 2041171, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643985057.553105151\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 2041171, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### VAL AVERAGE FUSION FOLD 4 OOF AUC with TTA = 0.920\n",
      "#### VAL WEIGHTED AVERAGE FOLD 4 OOF AUC with TTA = 0.923\n",
      "#########################\n",
      "#### FOLD 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:31:19.988630: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.099201: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.181568: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.253806: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.330641: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.412758: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.536204: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.624145: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.701765: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.775110: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.848322: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:20.927409: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.001536: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.120185: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.202360: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.289813: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.364910: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.455551: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.528015: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.659581: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.734856: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.826806: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.903876: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:21.977315: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:22.056308: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:22.131448: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Using 2018+2017 external data\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:31:22.205462: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2022-02-04 14:31:22.279504: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 305s 957ms/step - loss: 0.6452 - auc: 0.5592 - val_loss: 0.4985 - val_auc: 0.6393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:38:16.321718: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 2243330, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643985496.321618785\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 2243330, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 121s 852ms/step - loss: 0.2749 - auc: 0.7374 - val_loss: 0.1691 - val_auc: 0.8226\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 121s 851ms/step - loss: 0.2289 - auc: 0.8754 - val_loss: 0.1661 - val_auc: 0.8702\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 121s 849ms/step - loss: 0.2221 - auc: 0.9077 - val_loss: 0.1623 - val_auc: 0.8870\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 120s 847ms/step - loss: 0.2095 - auc: 0.9163 - val_loss: 0.1645 - val_auc: 0.8629\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 120s 845ms/step - loss: 0.2058 - auc: 0.9272 - val_loss: 0.1623 - val_auc: 0.9003\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.1973 - auc: 0.9437 - val_loss: 0.1589 - val_auc: 0.8915\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 120s 845ms/step - loss: 0.1945 - auc: 0.9486 - val_loss: 0.1595 - val_auc: 0.9028\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.1864 - auc: 0.9569 - val_loss: 0.1590 - val_auc: 0.8968\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 120s 844ms/step - loss: 0.1830 - auc: 0.9630 - val_loss: 0.1577 - val_auc: 0.8830\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 0.1755 - auc: 0.9706 - val_loss: 0.1575 - val_auc: 0.8676\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 120s 845ms/step - loss: 0.1709 - auc: 0.9758 - val_loss: 0.1591 - val_auc: 0.8888\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 141s 496ms/step - loss: 0.3677 - auc: 0.6159 - val_loss: 0.1715 - val_auc: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:03:23.563904: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 2340411, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643987003.563822615\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 2340411, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 69s 483ms/step - loss: 0.2317 - auc: 0.8621 - val_loss: 0.1683 - val_auc: 0.8294\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 60s 422ms/step - loss: 0.2197 - auc: 0.8936 - val_loss: 0.1776 - val_auc: 0.8299\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 61s 426ms/step - loss: 0.2193 - auc: 0.8941 - val_loss: 0.1930 - val_auc: 0.8468\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 61s 431ms/step - loss: 0.2104 - auc: 0.9061 - val_loss: 0.2128 - val_auc: 0.8311\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 61s 431ms/step - loss: 0.2109 - auc: 0.9180 - val_loss: 0.2101 - val_auc: 0.8344\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 61s 432ms/step - loss: 0.2076 - auc: 0.9263 - val_loss: 0.1646 - val_auc: 0.8516\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 61s 430ms/step - loss: 0.2019 - auc: 0.9319 - val_loss: 0.1659 - val_auc: 0.8571\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 61s 430ms/step - loss: 0.1932 - auc: 0.9481 - val_loss: 0.1662 - val_auc: 0.8220\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 61s 430ms/step - loss: 0.1883 - auc: 0.9573 - val_loss: 0.1986 - val_auc: 0.8702\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 61s 429ms/step - loss: 0.1839 - auc: 0.9627 - val_loss: 0.1637 - val_auc: 0.8560\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 61s 427ms/step - loss: 0.1811 - auc: 0.9653 - val_loss: 0.1629 - val_auc: 0.8167\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 118s 497ms/step - loss: 0.4522 - auc: 0.5920 - val_loss: 0.1779 - val_auc: 0.6148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:16:58.825571: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 2408260, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643987818.825293774\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 2408260, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2423 - auc: 0.8520 - val_loss: 0.1765 - val_auc: 0.7909\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2236 - auc: 0.9007 - val_loss: 0.1680 - val_auc: 0.8596\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2130 - auc: 0.9117 - val_loss: 0.1878 - val_auc: 0.8530\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2083 - auc: 0.9281 - val_loss: 0.1693 - val_auc: 0.8438\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.2067 - auc: 0.9242 - val_loss: 0.1644 - val_auc: 0.8525\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 0.1966 - auc: 0.9437 - val_loss: 0.1636 - val_auc: 0.8726\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1932 - auc: 0.9488 - val_loss: 0.1699 - val_auc: 0.8626\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1828 - auc: 0.9649 - val_loss: 0.1657 - val_auc: 0.8123\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1738 - auc: 0.9722 - val_loss: 0.1646 - val_auc: 0.8493\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1664 - auc: 0.9802 - val_loss: 0.1759 - val_auc: 0.8737\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 63s 445ms/step - loss: 0.1638 - auc: 0.9804 - val_loss: 0.1647 - val_auc: 0.8273\n",
      "Epoch 1/12\n",
      "142/142 [==============================] - 285s 787ms/step - loss: 0.3084 - auc: 0.7075 - val_loss: 0.1802 - val_auc: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:33:28.741139: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 2477219, Output num: 0\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643988808.740813091\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 2477219, Output num: 0\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12\n",
      "142/142 [==============================] - 93s 655ms/step - loss: 0.2265 - auc: 0.8774 - val_loss: 0.1699 - val_auc: 0.7657\n",
      "Epoch 3/12\n",
      "142/142 [==============================] - 93s 657ms/step - loss: 0.2184 - auc: 0.8953 - val_loss: 0.1664 - val_auc: 0.8017\n",
      "Epoch 4/12\n",
      "142/142 [==============================] - 92s 651ms/step - loss: 0.2151 - auc: 0.9071 - val_loss: 0.1683 - val_auc: 0.7921\n",
      "Epoch 5/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.2130 - auc: 0.9070 - val_loss: 0.2148 - val_auc: 0.7421\n",
      "Epoch 6/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.2148 - auc: 0.9096 - val_loss: 0.1763 - val_auc: 0.8107\n",
      "Epoch 7/12\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 0.2050 - auc: 0.9315 - val_loss: 0.1724 - val_auc: 0.7439\n",
      "Epoch 8/12\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 0.1992 - auc: 0.9404 - val_loss: 0.1610 - val_auc: 0.8345\n",
      "Epoch 9/12\n",
      "142/142 [==============================] - 93s 652ms/step - loss: 0.1927 - auc: 0.9510 - val_loss: 0.1815 - val_auc: 0.8673\n",
      "Epoch 10/12\n",
      "142/142 [==============================] - 92s 649ms/step - loss: 0.1869 - auc: 0.9593 - val_loss: 0.1588 - val_auc: 0.8616\n",
      "Epoch 11/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.1790 - auc: 0.9653 - val_loss: 0.1609 - val_auc: 0.8289\n",
      "Epoch 12/12\n",
      "142/142 [==============================] - 92s 650ms/step - loss: 0.1719 - auc: 0.9757 - val_loss: 0.1669 - val_auc: 0.8211\n",
      "Predicting OOF with TTA...\n",
      "70/70 [==============================] - 99s 1s/step\n",
      "70/70 [==============================] - 82s 1s/step\n",
      "70/70 [==============================] - 75s 1s/step\n",
      "70/70 [==============================] - 112s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:57:26.546020: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 2575398, Output num: 1\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1643990246.545745049\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 2575398, Output num: 1\",\"grpc_status\":3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### VAL AVERAGE FUSION FOLD 5 OOF AUC with TTA = 0.906\n",
      "#### VAL WEIGHTED AVERAGE FOLD 5 OOF AUC with TTA = 0.908\n",
      "Time needed for training: 25701.236994743347\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\n",
    "VERBOSE = 1\n",
    "DISPLAY_PLOT = True\n",
    "\n",
    "skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\n",
    "oof_pred_val = []; oof_tar_val = []; oof_names_val = []; oof_folds_val = [] \n",
    "oof_pred_val_weighted = []\n",
    "\n",
    "\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(np.arange(15))):\n",
    "    \n",
    "    # DISPLAY FOLD INFO\n",
    "    if DEVICE=='TPU':\n",
    "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    print('#'*25); print('#### FOLD',fold+1)\n",
    "    #print('#### Image Size %i with EfficientNet B%i and batch_size %i'%\n",
    "    #      (IMG_SIZES[fold],EFF_NETS[fold],BATCH_SIZES[fold]*REPLICAS))\n",
    "    \n",
    "    # CREATE TRAIN AND VALIDATION SUBSETS\n",
    "    files_train = tf.io.gfile.glob([GCS_PATH[fold] + '/train%.2i*.tfrec'%x for x in idxT])\n",
    "    if INC2019[fold]:\n",
    "        files_train += tf.io.gfile.glob([GCS_PATH2[fold] + '/train%.2i*.tfrec'%x for x in idxT*2+1])\n",
    "        print('#### Using 2019 external data')\n",
    "    if INC2018[fold]:\n",
    "        files_train += tf.io.gfile.glob([GCS_PATH2[fold] + '/train%.2i*.tfrec'%x for x in idxT*2])\n",
    "        print('#### Using 2018+2017 external data')\n",
    "    np.random.shuffle(files_train); print('#'*25)\n",
    "    files_valid = tf.io.gfile.glob([GCS_PATH[fold] + '/train%.2i*.tfrec'%x for x in idxV])\n",
    "    files_test = tf.io.gfile.glob(GCS_PATH[fold] + '/test*.tfrec')\n",
    "  \n",
    "    # BUILD MODEL\n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        model1 = build_model_efn(dim=IMG_SIZES[fold],ef=EFF_NETS[fold])\n",
    "        model2 = build_InceptionV3(input_tensor=Input(shape=(IMG_SIZES[fold], IMG_SIZES[fold], 3)))\n",
    "        model3 = build_Xception(input_tensor=Input(shape=(IMG_SIZES[fold], IMG_SIZES[fold], 3)))\n",
    "        model4 = build_DenseNet201(input_tensor=Input(shape=(IMG_SIZES[fold], IMG_SIZES[fold], 3)))\n",
    "        \n",
    "    #SAVE BEST MODEL EACH FOLD\n",
    "    sv1 = tf.keras.callbacks.ModelCheckpoint(\n",
    "        'folds1-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "        save_weights_only=True, mode='min', save_freq='epoch')\n",
    "    sv2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "        'folds2-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "        save_weights_only=True, mode='min', save_freq='epoch')\n",
    "    sv3 = tf.keras.callbacks.ModelCheckpoint(\n",
    "        'folds3-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "        save_weights_only=True, mode='min', save_freq='epoch')\n",
    "    sv4 = tf.keras.callbacks.ModelCheckpoint(\n",
    "        'folds4-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "        save_weights_only=True, mode='min', save_freq='epoch')\n",
    "   \n",
    "    # TRAIN\n",
    "    print('Training...')\n",
    "    files_for_train = get_dataset(files_train, augment=True, shuffle=True, repeat=True,\n",
    "                dim=IMG_SIZES[fold], batch_size = BATCH_SIZES[fold])\n",
    "    files_for_validation = get_dataset(files_valid,augment=False,shuffle=False,\n",
    "                repeat=False,dim=IMG_SIZES[fold])\n",
    "   \n",
    "    history = model1.fit(\n",
    "        files_for_train, \n",
    "        epochs=EPOCHS[fold],\n",
    "        callbacks = [sv1,get_lr_callback(BATCH_SIZES[fold])], \n",
    "        steps_per_epoch=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS,\n",
    "        validation_data=files_for_validation,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    model1.load_weights('folds1-%i.h5'%fold)\n",
    "    history1 = model2.fit(\n",
    "        files_for_train, \n",
    "        epochs=EPOCHS[fold],\n",
    "        callbacks = [sv2,get_lr_callback(BATCH_SIZES[fold])], \n",
    "        steps_per_epoch=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS,\n",
    "        validation_data=files_for_validation,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    model2.load_weights('folds2-%i.h5'%fold)\n",
    "    history2 = model3.fit(\n",
    "        files_for_train, \n",
    "        epochs=EPOCHS[fold],\n",
    "        callbacks = [sv3,get_lr_callback(BATCH_SIZES[fold])], \n",
    "        steps_per_epoch=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS,\n",
    "        validation_data=files_for_validation,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    model3.load_weights('folds3-%i.h5'%fold)\n",
    "    history3 = model4.fit(\n",
    "        files_for_train, \n",
    "        epochs=EPOCHS[fold],\n",
    "        callbacks = [sv4,get_lr_callback(BATCH_SIZES[fold])], \n",
    "        steps_per_epoch=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS,\n",
    "        validation_data=files_for_validation,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    model4.load_weights('folds4-%i.h5'%fold)\n",
    "    \n",
    "    \n",
    "    # PREDICT OOF USING TTA\n",
    "    print('Predicting OOF with TTA...')\n",
    "    ds_valid = get_dataset(files_valid,labeled=False,return_image_names=False,augment=True,\n",
    "            repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold]*4)\n",
    "    ct_valid = count_data_items(files_valid); STEPS = TTA * ct_valid/BATCH_SIZES[fold]/4/REPLICAS\n",
    "    \n",
    "    pred1 = model1.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n",
    "    pred2 = model2.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n",
    "    pred3 = model3.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n",
    "    pred4 = model4.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,]  \n",
    "    \n",
    "    vect_pred1 =  np.mean(pred1.reshape((ct_valid,TTA),order='F'),axis=1)\n",
    "    vect_pred2 =  np.mean(pred2.reshape((ct_valid,TTA),order='F'),axis=1)\n",
    "    vect_pred3 =  np.mean(pred3.reshape((ct_valid,TTA),order='F'),axis=1)\n",
    "    vect_pred4 =  np.mean(pred4.reshape((ct_valid,TTA),order='F'),axis=1)\n",
    " \n",
    "    # Average of all outputs     \n",
    "    multiple_lists = [vect_pred1,vect_pred2,vect_pred3,vect_pred4]\n",
    "    arrays = [np.array(x) for x in multiple_lists]\n",
    "    average_vec = [np.mean(k) for k in zip(*arrays)]\n",
    "\n",
    "    oof_pred_val.append( average_vec )                 \n",
    "  \n",
    "    # Weighted of all outputs, given weight to the best models that gave best individual results\n",
    "    weights = [0.5,0.3,0.1,0.1]\n",
    "    weighted_vec = [np.average(k,weights=weights)  for k in zip(*arrays)]\n",
    "    \n",
    "    oof_pred_val_weighted.append(weighted_vec)\n",
    "    \n",
    "    # GET OOF TARGETS AND NAMES\n",
    "    ds_valid = get_dataset(files_valid, augment=False, repeat=False, dim=IMG_SIZES[fold],\n",
    "            labeled=True, return_image_names=True)\n",
    "    oof_tar_val.append( np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) )\n",
    "    oof_folds_val.append( np.ones_like(oof_tar_val[-1],dtype='int8')*fold )\n",
    "    ds = get_dataset(files_valid, augment=False, repeat=False, dim=IMG_SIZES[fold],\n",
    "                labeled=False, return_image_names=True)\n",
    "    oof_names_val.append( np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())]))\n",
    "    \n",
    "#     # PREDICT TEST USING TTA\n",
    "#     print('Predicting Test with TTA...')\n",
    "#     ds_test = get_dataset(files_test,labeled=False,return_image_names=False,augment=True,\n",
    "#             repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold]*4)\n",
    "#     ct_test = count_data_items(files_test); STEPS = TTA * ct_test/BATCH_SIZES[fold]/4/REPLICAS\n",
    "#     pred = model1.predict(ds_test,steps=STEPS,verbose=VERBOSE)[:TTA*ct_test,] \n",
    "#     oof_pred_test.append( np.mean(pred.reshape((ct_test,TTA),order='F'),axis=1) )  \n",
    "    \n",
    "#     # GET TEST TARGETS AND NAMES\n",
    "#     ds_test = get_dataset(files_test, augment=False, repeat=False, dim=IMG_SIZES[fold],\n",
    "#             labeled=True, return_image_names=True)\n",
    "#     oof_tar_test.append( np.array([target.numpy() for img, target in iter(ds_test.unbatch())]) )\n",
    "#     oof_folds_test.append( np.ones_like(oof_tar_test[-1],dtype='int8')*fold )\n",
    "#     ds = get_dataset(files_test, augment=False, repeat=False, dim=IMG_SIZES[fold],\n",
    "#                 labeled=False, return_image_names=True)\n",
    "#     oof_names_test.append( np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())]))\n",
    "   \n",
    "    \n",
    "    # REPORT RESULTS\n",
    "    auc_val_average = roc_auc_score(oof_tar_val[-1],oof_pred_val[-1])\n",
    "    auc_val_weighted = roc_auc_score(oof_tar_val[-1],oof_pred_val_weighted[-1])\n",
    "   \n",
    "    print('#### VAL AVERAGE FUSION FOLD %i OOF AUC with TTA = %.3f'%(fold+1,auc_val_average))\n",
    "    print('#### VAL WEIGHTED AVERAGE FOLD %i OOF AUC with TTA = %.3f'%(fold+1,auc_val_weighted))\n",
    " \n",
    "   \n",
    "end = time.time()\n",
    "print(\"Time needed for training:\",end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91bdee1",
   "metadata": {
    "papermill": {
     "duration": 11.265835,
     "end_time": "2022-02-04T15:58:01.848850",
     "exception": false,
     "start_time": "2022-02-04T15:57:50.583015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculate OOF AUC\n",
    "The OOF (out of fold) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ce87b",
   "metadata": {
    "papermill": {
     "duration": 11.171614,
     "end_time": "2022-02-04T15:58:24.268299",
     "exception": false,
     "start_time": "2022-02-04T15:58:13.096685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Validation dataset average for K folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc815fda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-04T15:58:46.590812Z",
     "iopub.status.busy": "2022-02-04T15:58:46.589782Z",
     "iopub.status.idle": "2022-02-04T15:58:46.861877Z",
     "shell.execute_reply": "2022-02-04T15:58:46.861378Z",
     "shell.execute_reply.started": "2022-02-03T19:26:34.499663Z"
    },
    "papermill": {
     "duration": 11.508531,
     "end_time": "2022-02-04T15:58:46.862019",
     "exception": false,
     "start_time": "2022-02-04T15:58:35.353488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Late fusion average Overall OOF AUC with TTA = 0.919\n",
      "Val Late fusion average Overall OOF AUC with TTA = 0.920\n",
      "AVERAGED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.98      1.00      0.99     32111\n",
      "    melanoma       0.73      0.11      0.20       581\n",
      "\n",
      "    accuracy                           0.98     32692\n",
      "   macro avg       0.86      0.56      0.59     32692\n",
      "weighted avg       0.98      0.98      0.98     32692\n",
      "\n",
      "AVERAGE WEIGHTED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.98      1.00      0.99     32111\n",
      "    melanoma       0.66      0.12      0.20       581\n",
      "\n",
      "    accuracy                           0.98     32692\n",
      "   macro avg       0.82      0.56      0.60     32692\n",
      "weighted avg       0.98      0.98      0.98     32692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# COMPUTE OVERALL OOF AUC\n",
    "oof = np.concatenate(oof_pred_val); true = np.concatenate(oof_tar_val);\n",
    "oof_weigted = np.concatenate(oof_pred_val_weighted)\n",
    "names = np.concatenate(oof_names_val); folds = np.concatenate(oof_folds_val)\n",
    "auc_avg = roc_auc_score(true,oof)\n",
    "auc_avg_weighted = roc_auc_score(true,oof_weigted)\n",
    "print('Val Late fusion average Overall OOF AUC with TTA = %.3f'%auc_avg)\n",
    "print('Val Late fusion average Overall OOF AUC with TTA = %.3f'%auc_avg_weighted)\n",
    "preds= []\n",
    "for pred in oof:\n",
    "    if pred > 0.5:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)\n",
    "target_names = ['benign', 'melanoma']\n",
    "print(\"AVERAGED\")\n",
    "print(classification_report(true, preds, target_names=target_names))\n",
    "\n",
    "#### WEIGHTED \n",
    "preds= []\n",
    "for pred in oof_weigted:\n",
    "    if pred > 0.5:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)\n",
    "target_names = ['benign', 'melanoma']\n",
    "print(\"AVERAGE WEIGHTED\")\n",
    "print(classification_report(true, preds, target_names=target_names))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25816.742779,
   "end_time": "2022-02-04T15:59:00.855316",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-04T08:48:44.112537",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
