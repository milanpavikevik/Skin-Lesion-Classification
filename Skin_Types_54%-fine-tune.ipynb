{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skin-Types-Ext-RAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milanpavikevik/Skin-Lesion-Classification/blob/main/Skin_Types_54%25-fine-tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL2tzXOzHS9b",
        "outputId": "c7e490b7-5713-445c-a386-bda852fc490c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhTMJR9ZHTGF",
        "outputId": "3d64ecf9-500f-40b0-a1ab-a53b3bdd46ef"
      },
      "source": [
        "import warnings                        # To ignore any warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "%matplotlib inline\r\n",
        "%pylab inline\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "import itertools\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# Audio\r\n",
        "import librosa\r\n",
        "import librosa.display\r\n",
        "\r\n",
        "# Scikit learn\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.utils import class_weight\r\n",
        "\r\n",
        "# Keras\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, MaxPool2D\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wEiZ7VZQiVD"
      },
      "source": [
        "testiraj golemina na slika 768x768 , 512x512 , 384x384 , 256x256 , 192x192"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUMaUf0lHTJL",
        "outputId": "5d4f129a-343d-4b8f-bd61-85f287c0d2ab"
      },
      "source": [
        "INPUT_DIR = '/content/drive/MyDrive/Skin-Lesion/**'\r\n",
        " \r\n",
        "dataset = []\r\n",
        "for filename in glob.iglob(INPUT_DIR):\r\n",
        "    kolkuPoKlasa=0\r\n",
        "    print(filename)\r\n",
        "    for f in glob.iglob(filename+'/**'):\r\n",
        "      #print(f)\r\n",
        "      kolkuPoKlasa+=1\r\n",
        "      if (kolkuPoKlasa > 1000):\r\n",
        "        kolkuPoKlasa=0\r\n",
        "        break\r\n",
        "        \r\n",
        "    \r\n",
        "      \r\n",
        "      image= cv2.imread( f, cv2.COLOR_BGR2RGB)\r\n",
        "      image=cv2.resize(image, (256, 256),interpolation = cv2.INTER_AREA)\r\n",
        "      image=np.array(image)\r\n",
        "      image = image.astype('float32')\r\n",
        "      image /= 255 \r\n",
        "      \r\n",
        "      class_name = filename.split('/')[-1]\r\n",
        "      \r\n",
        "      dataset.append([image,class_name])\r\n",
        "      \r\n",
        "      \r\n",
        "    \r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Skin-Lesion/BCC\n",
            "/content/drive/MyDrive/Skin-Lesion/DF\n",
            "/content/drive/MyDrive/Skin-Lesion/AK\n",
            "/content/drive/MyDrive/Skin-Lesion/BKL\n",
            "/content/drive/MyDrive/Skin-Lesion/NV\n",
            "/content/drive/MyDrive/Skin-Lesion/VASC\n",
            "/content/drive/MyDrive/Skin-Lesion/MEL\n",
            "/content/drive/MyDrive/Skin-Lesion/SCC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YStzGE87HTMy",
        "outputId": "30ad3b68-bb71-4446-9e1b-20f2cc4d9608"
      },
      "source": [
        "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\r\n",
        "x_train = []\r\n",
        "y_train = []\r\n",
        "for img,klasa in train:\r\n",
        "  x_train.append(img)\r\n",
        "  y_train.append(klasa)\r\n",
        "\r\n",
        "x_test = []\r\n",
        "y_test = []\r\n",
        "for img,klasa in test[:int(len(test)*0.5)]:\r\n",
        "  x_test.append(img)\r\n",
        "  y_test.append(klasa)\r\n",
        "\r\n",
        "\r\n",
        "x_val = []\r\n",
        "y_val = []\r\n",
        "for img,klasa in test[int(len(test)*0.5):]:\r\n",
        "  x_val.append(img)\r\n",
        "  y_val.append(klasa)\r\n",
        "\r\n",
        "print(len(x_train),len(y_train))\r\n",
        "print(len(y_test),len(y_test))\r\n",
        "print(len(x_val),len(y_val))\r\n",
        "\r\n",
        "encoder = LabelEncoder()\r\n",
        "encoder.fit(y_train)\r\n",
        "\r\n",
        "y_train = encoder.transform(y_train)\r\n",
        "\r\n",
        "y_test =  encoder.transform(y_test)\r\n",
        "y_val =   encoder.transform(y_val)\r\n",
        "\r\n",
        "\r\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\r\n",
        "\r\n",
        "\r\n",
        "class_weights = {i : class_weights[i] for i in range(8)}\r\n",
        "\r\n",
        "print(class_weight)\r\n",
        "\r\n",
        "x_test = np.asarray(x_test)\r\n",
        "x_val = np.asarray(x_val)\r\n",
        "x_train = np.asarray(x_train)\r\n",
        "\r\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\r\n",
        "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 3)\r\n",
        "\r\n",
        "y_train = to_categorical(y_train)\r\n",
        "y_test = to_categorical(y_test)\r\n",
        "y_val = to_categorical(y_val)\r\n",
        "\r\n",
        "print(\"X train:\", x_train.shape)\r\n",
        "print(\"Y train:\", y_train.shape)\r\n",
        "print(\"X test:\", x_test.shape)\r\n",
        "print(\"Y test:\", y_test.shape)\r\n",
        "\r\n",
        "print(\"X validation:\", x_val.shape)\r\n",
        "print(\"Y validation:\", y_val.shape)\r\n",
        "\r\n",
        "print(class_weights)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4789 4789\n",
            "599 599\n",
            "599 599\n",
            "<module 'sklearn.utils.class_weight' from '/usr/local/lib/python3.7/dist-packages/sklearn/utils/class_weight.py'>\n",
            "X train: (4789, 256, 256, 3)\n",
            "Y train: (4789, 8)\n",
            "X test: (599, 256, 256, 3)\n",
            "Y test: (599, 8)\n",
            "X validation: (599, 256, 256, 3)\n",
            "Y validation: (599, 8)\n",
            "{0: 0.8479107648725213, 1: 0.7596763959390863, 2: 0.7492177722152691, 3: 3.401278409090909, 4: 0.7363161131611317, 5: 0.7436335403726708, 6: 1.2093434343434344, 7: 2.8919082125603865}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "_SmbIOPmHTPC",
        "outputId": "f560b462-75c5-42e4-f8e1-eae347beea1d"
      },
      "source": [
        "import matplotlib\r\n",
        "matplotlib.rcParams['figure.figsize'] = (14, 5)\r\n",
        "matplotlib.rcParams['font.size'] = 12\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "num_classes = 8\r\n",
        "\r\n",
        "xlass=[]\r\n",
        "\r\n",
        "for row in dataset:\r\n",
        "  xlass.append(row[1])\r\n",
        "print(len(xlass))\r\n",
        "xlass = pd.DataFrame(xlass)\r\n",
        "\r\n",
        "class_counts = xlass.value_counts()\r\n",
        "\r\n",
        "cmap = plt.cm.get_cmap(plt.cm.Set3, 10)\r\n",
        "colors = [cmap(i) for i in range(num_classes)]\r\n",
        "class_ticks = ['NV','MEL','BKL','BCC','AK','SCC','VASC','DF']\r\n",
        "plt.barh(range(num_classes)[::-1], class_counts, tick_label=class_ticks,\r\n",
        "         color=colors)\r\n",
        "plt.title('Class distribution of dataset')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "xlass=[]\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Rm11BCtW_Q",
        "outputId": "91984eee-ff46-4d68-93c2-bdeb027ff7c4"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3]),\r\n",
        "                 activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=2))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=2))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=2))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=2))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(GlobalAveragePooling2D())\r\n",
        "\r\n",
        "model.add(Dense(len(encoder.classes_), activation='softmax'))\r\n",
        "model.summary()\r\n",
        "\r\n",
        "adam = keras.optimizers.Adam(learning_rate=0.001)\r\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 255, 255, 16)      208       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 127, 127, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 127, 127, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 126, 126, 32)      2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 62, 62, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 128)       32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 44,472\n",
            "Trainable params: 44,472\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4meu5npDtXK3",
        "outputId": "fd9cc792-1028-4000-931f-ca2b8336ac92"
      },
      "source": [
        "history = model.fit(x_train, y_train,\r\n",
        "                    batch_size=128,\r\n",
        "                    epochs=130,\r\n",
        "                    validation_data=(x_val, y_val),\r\n",
        "                    class_weight=class_weights)\r\n",
        "\r\n",
        "\r\n",
        "model_name = \"/content/skin-classical.h5\"\r\n",
        "model.save(model_name)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/130\n",
            "38/38 [==============================] - 128s 3s/step - loss: 1.9706 - accuracy: 0.2076 - val_loss: 1.9536 - val_accuracy: 0.2154\n",
            "Epoch 2/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.9199 - accuracy: 0.2236 - val_loss: 1.9228 - val_accuracy: 0.2404\n",
            "Epoch 3/130\n",
            "38/38 [==============================] - 127s 3s/step - loss: 1.9167 - accuracy: 0.2193 - val_loss: 1.9168 - val_accuracy: 0.2304\n",
            "Epoch 4/130\n",
            "38/38 [==============================] - 129s 3s/step - loss: 1.8940 - accuracy: 0.2360 - val_loss: 1.8989 - val_accuracy: 0.2104\n",
            "Epoch 5/130\n",
            "38/38 [==============================] - 127s 3s/step - loss: 1.8861 - accuracy: 0.2458 - val_loss: 1.8927 - val_accuracy: 0.2321\n",
            "Epoch 6/130\n",
            "38/38 [==============================] - 127s 3s/step - loss: 1.8631 - accuracy: 0.2506 - val_loss: 1.9088 - val_accuracy: 0.2053\n",
            "Epoch 7/130\n",
            "38/38 [==============================] - 128s 3s/step - loss: 1.8596 - accuracy: 0.2600 - val_loss: 1.8540 - val_accuracy: 0.2471\n",
            "Epoch 8/130\n",
            "38/38 [==============================] - 125s 3s/step - loss: 1.8289 - accuracy: 0.2708 - val_loss: 1.8440 - val_accuracy: 0.2521\n",
            "Epoch 9/130\n",
            "38/38 [==============================] - 127s 3s/step - loss: 1.8067 - accuracy: 0.2823 - val_loss: 1.8297 - val_accuracy: 0.2654\n",
            "Epoch 10/130\n",
            "38/38 [==============================] - 133s 4s/step - loss: 1.7975 - accuracy: 0.2796 - val_loss: 1.8243 - val_accuracy: 0.2671\n",
            "Epoch 11/130\n",
            "38/38 [==============================] - 127s 3s/step - loss: 1.7881 - accuracy: 0.2769 - val_loss: 1.8205 - val_accuracy: 0.2705\n",
            "Epoch 12/130\n",
            "38/38 [==============================] - 130s 3s/step - loss: 1.7687 - accuracy: 0.2959 - val_loss: 1.8029 - val_accuracy: 0.2738\n",
            "Epoch 13/130\n",
            "38/38 [==============================] - 126s 3s/step - loss: 1.7576 - accuracy: 0.2992 - val_loss: 1.7927 - val_accuracy: 0.2788\n",
            "Epoch 14/130\n",
            "38/38 [==============================] - 126s 3s/step - loss: 1.7494 - accuracy: 0.2953 - val_loss: 1.7777 - val_accuracy: 0.2838\n",
            "Epoch 15/130\n",
            "38/38 [==============================] - 128s 3s/step - loss: 1.7464 - accuracy: 0.2953 - val_loss: 1.7868 - val_accuracy: 0.2871\n",
            "Epoch 16/130\n",
            "38/38 [==============================] - 128s 3s/step - loss: 1.7462 - accuracy: 0.2900 - val_loss: 1.7884 - val_accuracy: 0.2821\n",
            "Epoch 17/130\n",
            "38/38 [==============================] - 129s 3s/step - loss: 1.7246 - accuracy: 0.3051 - val_loss: 1.7717 - val_accuracy: 0.2821\n",
            "Epoch 18/130\n",
            "38/38 [==============================] - 129s 3s/step - loss: 1.7215 - accuracy: 0.3028 - val_loss: 1.7738 - val_accuracy: 0.3072\n",
            "Epoch 19/130\n",
            "38/38 [==============================] - 136s 4s/step - loss: 1.7176 - accuracy: 0.3049 - val_loss: 1.7515 - val_accuracy: 0.3072\n",
            "Epoch 20/130\n",
            "38/38 [==============================] - 138s 4s/step - loss: 1.7063 - accuracy: 0.3241 - val_loss: 1.7753 - val_accuracy: 0.3055\n",
            "Epoch 21/130\n",
            "38/38 [==============================] - 133s 4s/step - loss: 1.7181 - accuracy: 0.3151 - val_loss: 1.7681 - val_accuracy: 0.3239\n",
            "Epoch 22/130\n",
            "38/38 [==============================] - 132s 3s/step - loss: 1.7046 - accuracy: 0.3199 - val_loss: 1.7715 - val_accuracy: 0.3055\n",
            "Epoch 23/130\n",
            "38/38 [==============================] - 130s 3s/step - loss: 1.6960 - accuracy: 0.3180 - val_loss: 1.7478 - val_accuracy: 0.2972\n",
            "Epoch 24/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6886 - accuracy: 0.3234 - val_loss: 1.7575 - val_accuracy: 0.3038\n",
            "Epoch 25/130\n",
            "38/38 [==============================] - 130s 3s/step - loss: 1.6976 - accuracy: 0.3220 - val_loss: 1.7870 - val_accuracy: 0.3055\n",
            "Epoch 26/130\n",
            "38/38 [==============================] - 137s 4s/step - loss: 1.7003 - accuracy: 0.3095 - val_loss: 1.7805 - val_accuracy: 0.3222\n",
            "Epoch 27/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6869 - accuracy: 0.3326 - val_loss: 1.7508 - val_accuracy: 0.3205\n",
            "Epoch 28/130\n",
            "38/38 [==============================] - 137s 4s/step - loss: 1.6861 - accuracy: 0.3201 - val_loss: 1.7726 - val_accuracy: 0.3222\n",
            "Epoch 29/130\n",
            "38/38 [==============================] - 130s 3s/step - loss: 1.6751 - accuracy: 0.3283 - val_loss: 1.7269 - val_accuracy: 0.3072\n",
            "Epoch 30/130\n",
            "38/38 [==============================] - 129s 3s/step - loss: 1.6861 - accuracy: 0.3224 - val_loss: 1.7629 - val_accuracy: 0.3088\n",
            "Epoch 31/130\n",
            "38/38 [==============================] - 129s 3s/step - loss: 1.6708 - accuracy: 0.3230 - val_loss: 1.7334 - val_accuracy: 0.3339\n",
            "Epoch 32/130\n",
            "38/38 [==============================] - 128s 3s/step - loss: 1.6915 - accuracy: 0.3268 - val_loss: 1.7530 - val_accuracy: 0.3389\n",
            "Epoch 33/130\n",
            "38/38 [==============================] - 128s 3s/step - loss: 1.6711 - accuracy: 0.3251 - val_loss: 1.7440 - val_accuracy: 0.3289\n",
            "Epoch 34/130\n",
            "38/38 [==============================] - 129s 3s/step - loss: 1.6771 - accuracy: 0.3234 - val_loss: 1.7450 - val_accuracy: 0.3172\n",
            "Epoch 35/130\n",
            "38/38 [==============================] - 129s 3s/step - loss: 1.6643 - accuracy: 0.3270 - val_loss: 1.7403 - val_accuracy: 0.3406\n",
            "Epoch 36/130\n",
            "38/38 [==============================] - 130s 3s/step - loss: 1.6779 - accuracy: 0.3214 - val_loss: 1.7829 - val_accuracy: 0.3088\n",
            "Epoch 37/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6614 - accuracy: 0.3166 - val_loss: 1.7485 - val_accuracy: 0.3389\n",
            "Epoch 38/130\n",
            "38/38 [==============================] - 132s 3s/step - loss: 1.6598 - accuracy: 0.3287 - val_loss: 1.7430 - val_accuracy: 0.3272\n",
            "Epoch 39/130\n",
            "38/38 [==============================] - 134s 4s/step - loss: 1.6579 - accuracy: 0.3226 - val_loss: 1.7200 - val_accuracy: 0.3306\n",
            "Epoch 40/130\n",
            "38/38 [==============================] - 133s 3s/step - loss: 1.6551 - accuracy: 0.3278 - val_loss: 1.7501 - val_accuracy: 0.3255\n",
            "Epoch 41/130\n",
            "38/38 [==============================] - 132s 3s/step - loss: 1.6696 - accuracy: 0.3339 - val_loss: 1.7450 - val_accuracy: 0.3289\n",
            "Epoch 42/130\n",
            "38/38 [==============================] - 143s 4s/step - loss: 1.6613 - accuracy: 0.3255 - val_loss: 1.7283 - val_accuracy: 0.3205\n",
            "Epoch 43/130\n",
            "38/38 [==============================] - 138s 4s/step - loss: 1.6412 - accuracy: 0.3333 - val_loss: 1.7329 - val_accuracy: 0.3272\n",
            "Epoch 44/130\n",
            "38/38 [==============================] - 132s 3s/step - loss: 1.6456 - accuracy: 0.3297 - val_loss: 1.7395 - val_accuracy: 0.3339\n",
            "Epoch 45/130\n",
            "38/38 [==============================] - 134s 4s/step - loss: 1.6587 - accuracy: 0.3333 - val_loss: 1.7578 - val_accuracy: 0.3272\n",
            "Epoch 46/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6538 - accuracy: 0.3268 - val_loss: 1.7422 - val_accuracy: 0.3222\n",
            "Epoch 47/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6522 - accuracy: 0.3234 - val_loss: 1.7256 - val_accuracy: 0.3222\n",
            "Epoch 48/130\n",
            "38/38 [==============================] - 135s 4s/step - loss: 1.6494 - accuracy: 0.3326 - val_loss: 1.7469 - val_accuracy: 0.3289\n",
            "Epoch 49/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6413 - accuracy: 0.3406 - val_loss: 1.7334 - val_accuracy: 0.3239\n",
            "Epoch 50/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6442 - accuracy: 0.3402 - val_loss: 1.7288 - val_accuracy: 0.3255\n",
            "Epoch 51/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6399 - accuracy: 0.3285 - val_loss: 1.7444 - val_accuracy: 0.3289\n",
            "Epoch 52/130\n",
            "38/38 [==============================] - 132s 3s/step - loss: 1.6420 - accuracy: 0.3289 - val_loss: 1.7364 - val_accuracy: 0.3172\n",
            "Epoch 53/130\n",
            "38/38 [==============================] - 133s 4s/step - loss: 1.6363 - accuracy: 0.3393 - val_loss: 1.7227 - val_accuracy: 0.3406\n",
            "Epoch 54/130\n",
            "38/38 [==============================] - 135s 4s/step - loss: 1.6425 - accuracy: 0.3316 - val_loss: 1.7262 - val_accuracy: 0.3339\n",
            "Epoch 55/130\n",
            "38/38 [==============================] - 133s 4s/step - loss: 1.6255 - accuracy: 0.3316 - val_loss: 1.7457 - val_accuracy: 0.3139\n",
            "Epoch 56/130\n",
            "38/38 [==============================] - 130s 3s/step - loss: 1.6511 - accuracy: 0.3264 - val_loss: 1.7434 - val_accuracy: 0.3456\n",
            "Epoch 57/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6339 - accuracy: 0.3333 - val_loss: 1.7292 - val_accuracy: 0.3406\n",
            "Epoch 58/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6325 - accuracy: 0.3253 - val_loss: 1.7475 - val_accuracy: 0.3222\n",
            "Epoch 59/130\n",
            "38/38 [==============================] - 134s 4s/step - loss: 1.6301 - accuracy: 0.3372 - val_loss: 1.7345 - val_accuracy: 0.3155\n",
            "Epoch 60/130\n",
            "38/38 [==============================] - 134s 4s/step - loss: 1.6297 - accuracy: 0.3351 - val_loss: 1.7176 - val_accuracy: 0.3289\n",
            "Epoch 61/130\n",
            "38/38 [==============================] - 133s 4s/step - loss: 1.6226 - accuracy: 0.3360 - val_loss: 1.7248 - val_accuracy: 0.3422\n",
            "Epoch 62/130\n",
            "38/38 [==============================] - 136s 4s/step - loss: 1.6284 - accuracy: 0.3383 - val_loss: 1.7439 - val_accuracy: 0.3205\n",
            "Epoch 63/130\n",
            "38/38 [==============================] - 132s 3s/step - loss: 1.6238 - accuracy: 0.3333 - val_loss: 1.7243 - val_accuracy: 0.3356\n",
            "Epoch 64/130\n",
            "38/38 [==============================] - 133s 4s/step - loss: 1.6149 - accuracy: 0.3414 - val_loss: 1.7246 - val_accuracy: 0.3272\n",
            "Epoch 65/130\n",
            "38/38 [==============================] - 132s 3s/step - loss: 1.6197 - accuracy: 0.3425 - val_loss: 1.7418 - val_accuracy: 0.3222\n",
            "Epoch 66/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6278 - accuracy: 0.3485 - val_loss: 1.7339 - val_accuracy: 0.3356\n",
            "Epoch 67/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6149 - accuracy: 0.3354 - val_loss: 1.7316 - val_accuracy: 0.3406\n",
            "Epoch 68/130\n",
            "38/38 [==============================] - 131s 3s/step - loss: 1.6183 - accuracy: 0.3418 - val_loss: 1.7445 - val_accuracy: 0.3306\n",
            "Epoch 69/130\n",
            "38/38 [==============================] - 132s 3s/step - loss: 1.6089 - accuracy: 0.3429 - val_loss: 1.7337 - val_accuracy: 0.3155\n",
            "Epoch 70/130\n",
            "38/38 [==============================] - 130s 3s/step - loss: 1.6226 - accuracy: 0.3374 - val_loss: 1.7197 - val_accuracy: 0.3356\n",
            "Epoch 71/130\n",
            "38/38 [==============================] - 130s 3s/step - loss: 1.6155 - accuracy: 0.3512 - val_loss: 1.7518 - val_accuracy: 0.3122\n",
            "Epoch 72/130\n",
            "38/38 [==============================] - 128s 3s/step - loss: 1.6052 - accuracy: 0.3410 - val_loss: 1.7669 - val_accuracy: 0.3105\n",
            "Epoch 73/130\n",
            "38/38 [==============================] - 128s 3s/step - loss: 1.6232 - accuracy: 0.3548 - val_loss: 1.7540 - val_accuracy: 0.3406\n",
            "Epoch 74/130\n",
            "38/38 [==============================] - 126s 3s/step - loss: 1.6088 - accuracy: 0.3414 - val_loss: 1.7412 - val_accuracy: 0.3372\n",
            "Epoch 75/130\n",
            "22/38 [================>.............] - ETA: 52s - loss: 1.5554 - accuracy: 0.3590"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDFPvny8t_oG"
      },
      "source": [
        "predictions = model.predict(x_test, verbose=1)\r\n",
        "\r\n",
        "y_true, y_pred = [],[]\r\n",
        "classes = encoder.classes_\r\n",
        "for idx, prediction in enumerate(predictions): \r\n",
        "    y_true.append(classes[np.argmax(y_test[idx])])\r\n",
        "    y_pred.append(classes[np.argmax(prediction)])\r\n",
        "    \r\n",
        "print(classification_report(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWEjDP6_5UHu"
      },
      "source": [
        "model = Sequential()\r\n",
        "\r\n",
        "# convolutional layer\r\n",
        "model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])))\r\n",
        "\r\n",
        "# convolutional layer\r\n",
        "model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\r\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\r\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "# flatten output of conv\r\n",
        "model.add(Flatten())\r\n",
        "\r\n",
        "# hidden layer\r\n",
        "model.add(Dense(500, activation='relu'))\r\n",
        "model.add(Dropout(0.4))\r\n",
        "model.add(Dense(250, activation='relu'))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "# output layer\r\n",
        "model.add(Dense(8, activation='softmax'))\r\n",
        "\r\n",
        "# compiling the sequential model\r\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\r\n",
        "\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsCtEALu5URe",
        "outputId": "52f9f789-a185-48f0-a37a-f121c2f37cad"
      },
      "source": [
        "history1 = model.fit(x_train, y_train,\r\n",
        "                    batch_size=64,\r\n",
        "                    epochs=20,\r\n",
        "                    validation_data=(x_val, y_val),class_weight=class_weights)\r\n",
        "\r\n",
        "\r\n",
        "model_name = \"/content/skin-type-1.h5\"\r\n",
        "model.save(model_name)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "75/75 [==============================] - 24s 326ms/step - loss: 0.5746 - accuracy: 0.7887 - val_loss: 2.5812 - val_accuracy: 0.3322\n",
            "Epoch 2/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.4381 - accuracy: 0.8415 - val_loss: 2.7360 - val_accuracy: 0.3122\n",
            "Epoch 3/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.3563 - accuracy: 0.8693 - val_loss: 3.5429 - val_accuracy: 0.3306\n",
            "Epoch 4/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.2897 - accuracy: 0.8981 - val_loss: 3.4261 - val_accuracy: 0.3255\n",
            "Epoch 5/20\n",
            "75/75 [==============================] - 24s 326ms/step - loss: 0.2175 - accuracy: 0.9227 - val_loss: 3.5855 - val_accuracy: 0.3222\n",
            "Epoch 6/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.1822 - accuracy: 0.9363 - val_loss: 4.1743 - val_accuracy: 0.3122\n",
            "Epoch 7/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.1783 - accuracy: 0.9436 - val_loss: 3.9729 - val_accuracy: 0.3172\n",
            "Epoch 8/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.1472 - accuracy: 0.9564 - val_loss: 3.9869 - val_accuracy: 0.3222\n",
            "Epoch 9/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.1369 - accuracy: 0.9534 - val_loss: 4.2029 - val_accuracy: 0.3155\n",
            "Epoch 10/20\n",
            "75/75 [==============================] - 24s 326ms/step - loss: 0.1612 - accuracy: 0.9511 - val_loss: 4.5522 - val_accuracy: 0.3072\n",
            "Epoch 11/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.1350 - accuracy: 0.9628 - val_loss: 3.8055 - val_accuracy: 0.3372\n",
            "Epoch 12/20\n",
            "75/75 [==============================] - 24s 326ms/step - loss: 0.1076 - accuracy: 0.9733 - val_loss: 4.0590 - val_accuracy: 0.3439\n",
            "Epoch 13/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.2037 - accuracy: 0.9468 - val_loss: 3.7385 - val_accuracy: 0.3155\n",
            "Epoch 14/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.2280 - accuracy: 0.9399 - val_loss: 3.9432 - val_accuracy: 0.3122\n",
            "Epoch 15/20\n",
            "75/75 [==============================] - 24s 326ms/step - loss: 0.1534 - accuracy: 0.9603 - val_loss: 4.3769 - val_accuracy: 0.3222\n",
            "Epoch 16/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.0792 - accuracy: 0.9785 - val_loss: 4.4768 - val_accuracy: 0.3022\n",
            "Epoch 17/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.0868 - accuracy: 0.9804 - val_loss: 4.2944 - val_accuracy: 0.3105\n",
            "Epoch 18/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.0483 - accuracy: 0.9843 - val_loss: 4.7980 - val_accuracy: 0.3055\n",
            "Epoch 19/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.0552 - accuracy: 0.9837 - val_loss: 4.3142 - val_accuracy: 0.3389\n",
            "Epoch 20/20\n",
            "75/75 [==============================] - 24s 325ms/step - loss: 0.0614 - accuracy: 0.9835 - val_loss: 4.9125 - val_accuracy: 0.3139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lda0p1H-qRCl",
        "outputId": "80ca5c0f-08f3-470c-e032-bec9c49b609f"
      },
      "source": [
        "predictions = model.predict(x_test, verbose=1)\r\n",
        "\r\n",
        "y_true, y_pred = [],[]\r\n",
        "classes = encoder.classes_\r\n",
        "for idx, prediction in enumerate(predictions): \r\n",
        "    y_true.append(classes[np.argmax(y_test[idx])])\r\n",
        "    y_pred.append(classes[np.argmax(prediction)])\r\n",
        "    \r\n",
        "print(classification_report(y_pred, y_true))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 1s 41ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AK       0.28      0.31      0.29        71\n",
            "         BCC       0.24      0.33      0.28        82\n",
            "         BKL       0.35      0.31      0.33       119\n",
            "          DF       0.09      0.23      0.13        13\n",
            "         MEL       0.43      0.32      0.37       123\n",
            "          NV       0.49      0.38      0.43       128\n",
            "         SCC       0.25      0.36      0.30        42\n",
            "        VASC       0.41      0.43      0.42        21\n",
            "\n",
            "    accuracy                           0.34       599\n",
            "   macro avg       0.32      0.33      0.32       599\n",
            "weighted avg       0.36      0.34      0.34       599\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxh5qfQv6LIh"
      },
      "source": [
        "hyper-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPb3EoGp5UUE",
        "outputId": "52673b2d-749a-49c8-aeb1-d8ee151bfc88"
      },
      "source": [
        "from keras.applications import VGG16\r\n",
        "\r\n",
        "# include top should be False to remove the softmax layer\r\n",
        "pretrained_model = VGG16(include_top=False, weights='imagenet')\r\n",
        "pretrained_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byX90SPN5UXo"
      },
      "source": [
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "vgg_features_train = pretrained_model.predict(x_train)\r\n",
        "vgg_features_val = pretrained_model.predict(x_val)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkIWRQtp6Tuf"
      },
      "source": [
        "train_target = y_train\r\n",
        "val_target = y_val"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51Buz-AG6TyG",
        "outputId": "b7126edb-9872-4d18-fb8f-da34a9cba353"
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\r\n",
        "model2 = Sequential()\r\n",
        "model2.add(Flatten(input_shape=(8,8,512)))\r\n",
        "model2.add(Dense(255, activation='relu'))\r\n",
        "model2.add(Dropout(0.5))\r\n",
        "model2.add(BatchNormalization())\r\n",
        "model2.add(Dense(8, activation='softmax'))\r\n",
        "\r\n",
        "# compile the model\r\n",
        "model2.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\r\n",
        "\r\n",
        "model2.summary()\r\n",
        "\r\n",
        "# train model using features generated from VGG16 model\r\n",
        "model2.fit(vgg_features_train, train_target, epochs=100, batch_size=128, validation_data=(vgg_features_val, val_target),class_weight=class_weights)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 255)               8356095   \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 255)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 255)               1020      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 2048      \n",
            "=================================================================\n",
            "Total params: 8,359,163\n",
            "Trainable params: 8,358,653\n",
            "Non-trainable params: 510\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 2.2597 - accuracy: 0.1788 - val_loss: 2.0557 - val_accuracy: 0.2404\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.8993 - accuracy: 0.2572 - val_loss: 1.8026 - val_accuracy: 0.3088\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.6924 - accuracy: 0.3262 - val_loss: 1.6886 - val_accuracy: 0.3907\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.5620 - accuracy: 0.3854 - val_loss: 1.7431 - val_accuracy: 0.3289\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.5695 - accuracy: 0.3856 - val_loss: 1.7341 - val_accuracy: 0.3673\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.4651 - accuracy: 0.4247 - val_loss: 1.7922 - val_accuracy: 0.2621\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.4119 - accuracy: 0.4540 - val_loss: 1.6382 - val_accuracy: 0.3940\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.3469 - accuracy: 0.4742 - val_loss: 1.7364 - val_accuracy: 0.3456\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.3409 - accuracy: 0.4699 - val_loss: 1.6834 - val_accuracy: 0.3422\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.2831 - accuracy: 0.4917 - val_loss: 1.5979 - val_accuracy: 0.4007\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.2542 - accuracy: 0.5032 - val_loss: 1.6604 - val_accuracy: 0.3539\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.2852 - accuracy: 0.5050 - val_loss: 1.5965 - val_accuracy: 0.3973\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.2383 - accuracy: 0.5046 - val_loss: 1.6984 - val_accuracy: 0.3656\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.2264 - accuracy: 0.5242 - val_loss: 1.6184 - val_accuracy: 0.3856\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.2222 - accuracy: 0.5137 - val_loss: 1.6309 - val_accuracy: 0.3756\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1765 - accuracy: 0.5258 - val_loss: 1.5794 - val_accuracy: 0.4007\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1150 - accuracy: 0.5521 - val_loss: 1.8867 - val_accuracy: 0.2938\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.2165 - accuracy: 0.5192 - val_loss: 1.7359 - val_accuracy: 0.3372\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1909 - accuracy: 0.5183 - val_loss: 1.5123 - val_accuracy: 0.4290\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1434 - accuracy: 0.5285 - val_loss: 1.5420 - val_accuracy: 0.4374\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0998 - accuracy: 0.5525 - val_loss: 1.5025 - val_accuracy: 0.4407\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0989 - accuracy: 0.5593 - val_loss: 1.6683 - val_accuracy: 0.3790\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.2123 - accuracy: 0.5183 - val_loss: 1.7198 - val_accuracy: 0.3923\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1995 - accuracy: 0.5103 - val_loss: 1.5249 - val_accuracy: 0.4257\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1402 - accuracy: 0.5272 - val_loss: 1.5463 - val_accuracy: 0.4407\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1490 - accuracy: 0.5101 - val_loss: 1.5685 - val_accuracy: 0.4023\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1025 - accuracy: 0.5443 - val_loss: 1.5121 - val_accuracy: 0.4691\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1016 - accuracy: 0.5478 - val_loss: 1.6877 - val_accuracy: 0.3773\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0594 - accuracy: 0.5633 - val_loss: 1.5464 - val_accuracy: 0.4274\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0442 - accuracy: 0.5698 - val_loss: 1.4990 - val_accuracy: 0.4174\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1461 - accuracy: 0.5251 - val_loss: 1.5450 - val_accuracy: 0.4090\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0258 - accuracy: 0.5559 - val_loss: 1.5066 - val_accuracy: 0.4441\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0626 - accuracy: 0.5541 - val_loss: 1.6004 - val_accuracy: 0.3990\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0406 - accuracy: 0.5713 - val_loss: 1.4700 - val_accuracy: 0.4775\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0704 - accuracy: 0.5541 - val_loss: 1.6000 - val_accuracy: 0.4257\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0774 - accuracy: 0.5400 - val_loss: 1.7204 - val_accuracy: 0.3723\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0537 - accuracy: 0.5517 - val_loss: 1.7643 - val_accuracy: 0.3506\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0681 - accuracy: 0.5399 - val_loss: 1.5791 - val_accuracy: 0.3940\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0104 - accuracy: 0.5708 - val_loss: 1.6538 - val_accuracy: 0.4023\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0202 - accuracy: 0.5676 - val_loss: 1.4851 - val_accuracy: 0.4574\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9900 - accuracy: 0.5855 - val_loss: 1.4863 - val_accuracy: 0.4624\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9523 - accuracy: 0.5940 - val_loss: 1.5650 - val_accuracy: 0.4174\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9325 - accuracy: 0.5940 - val_loss: 1.4976 - val_accuracy: 0.4391\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0037 - accuracy: 0.5696 - val_loss: 1.7714 - val_accuracy: 0.3573\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0513 - accuracy: 0.5593 - val_loss: 1.6849 - val_accuracy: 0.3940\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.0458 - accuracy: 0.5486 - val_loss: 1.5354 - val_accuracy: 0.4307\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0230 - accuracy: 0.5653 - val_loss: 1.5204 - val_accuracy: 0.4357\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0441 - accuracy: 0.5585 - val_loss: 1.5234 - val_accuracy: 0.4491\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9862 - accuracy: 0.5831 - val_loss: 1.4271 - val_accuracy: 0.4558\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9733 - accuracy: 0.5965 - val_loss: 1.5110 - val_accuracy: 0.4407\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9803 - accuracy: 0.5942 - val_loss: 1.5270 - val_accuracy: 0.4674\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9507 - accuracy: 0.6061 - val_loss: 1.5189 - val_accuracy: 0.4574\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9365 - accuracy: 0.6043 - val_loss: 1.5309 - val_accuracy: 0.4424\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9563 - accuracy: 0.5878 - val_loss: 1.4816 - val_accuracy: 0.4808\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8852 - accuracy: 0.6184 - val_loss: 1.4799 - val_accuracy: 0.4858\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9083 - accuracy: 0.6107 - val_loss: 1.4731 - val_accuracy: 0.4775\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9273 - accuracy: 0.6109 - val_loss: 1.7229 - val_accuracy: 0.4090\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9401 - accuracy: 0.6109 - val_loss: 1.5910 - val_accuracy: 0.4424\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9757 - accuracy: 0.5927 - val_loss: 1.5000 - val_accuracy: 0.4691\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8907 - accuracy: 0.6202 - val_loss: 1.5083 - val_accuracy: 0.4541\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9219 - accuracy: 0.6239 - val_loss: 1.5255 - val_accuracy: 0.4558\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8935 - accuracy: 0.6192 - val_loss: 1.5434 - val_accuracy: 0.4841\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9398 - accuracy: 0.6080 - val_loss: 1.6142 - val_accuracy: 0.4674\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8737 - accuracy: 0.6294 - val_loss: 1.5586 - val_accuracy: 0.4791\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8646 - accuracy: 0.6371 - val_loss: 1.5646 - val_accuracy: 0.4441\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8534 - accuracy: 0.6433 - val_loss: 1.5142 - val_accuracy: 0.4791\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8613 - accuracy: 0.6349 - val_loss: 1.5111 - val_accuracy: 0.4741\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8696 - accuracy: 0.6291 - val_loss: 2.3572 - val_accuracy: 0.3639\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.9403 - accuracy: 0.6078 - val_loss: 1.6462 - val_accuracy: 0.4424\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8520 - accuracy: 0.6294 - val_loss: 1.6441 - val_accuracy: 0.4491\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8550 - accuracy: 0.6346 - val_loss: 1.5703 - val_accuracy: 0.4708\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8653 - accuracy: 0.6291 - val_loss: 1.6484 - val_accuracy: 0.4508\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8569 - accuracy: 0.6514 - val_loss: 1.5288 - val_accuracy: 0.4608\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8052 - accuracy: 0.6640 - val_loss: 1.4772 - val_accuracy: 0.4725\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8194 - accuracy: 0.6540 - val_loss: 1.5799 - val_accuracy: 0.4791\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7872 - accuracy: 0.6678 - val_loss: 1.6204 - val_accuracy: 0.4758\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8598 - accuracy: 0.6506 - val_loss: 1.6258 - val_accuracy: 0.4424\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8284 - accuracy: 0.6499 - val_loss: 1.5861 - val_accuracy: 0.4641\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7881 - accuracy: 0.6603 - val_loss: 1.5068 - val_accuracy: 0.4841\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7470 - accuracy: 0.6970 - val_loss: 1.5756 - val_accuracy: 0.4791\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7401 - accuracy: 0.6927 - val_loss: 1.5739 - val_accuracy: 0.4658\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7373 - accuracy: 0.6839 - val_loss: 1.5737 - val_accuracy: 0.4875\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7628 - accuracy: 0.6775 - val_loss: 1.6919 - val_accuracy: 0.4307\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7998 - accuracy: 0.6635 - val_loss: 1.5708 - val_accuracy: 0.4608\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.8099 - accuracy: 0.6758 - val_loss: 1.7645 - val_accuracy: 0.4574\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7724 - accuracy: 0.6722 - val_loss: 1.6090 - val_accuracy: 0.4457\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7604 - accuracy: 0.6684 - val_loss: 1.6052 - val_accuracy: 0.4708\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7278 - accuracy: 0.7057 - val_loss: 1.6185 - val_accuracy: 0.4925\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7135 - accuracy: 0.7145 - val_loss: 1.6200 - val_accuracy: 0.5042\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7070 - accuracy: 0.6938 - val_loss: 1.5995 - val_accuracy: 0.4858\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7273 - accuracy: 0.6929 - val_loss: 1.5686 - val_accuracy: 0.4992\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.7145 - accuracy: 0.7025 - val_loss: 1.7802 - val_accuracy: 0.4942\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7042 - accuracy: 0.7059 - val_loss: 1.6400 - val_accuracy: 0.4858\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7051 - accuracy: 0.7045 - val_loss: 1.7572 - val_accuracy: 0.4407\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7358 - accuracy: 0.6853 - val_loss: 1.6603 - val_accuracy: 0.4808\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7112 - accuracy: 0.6978 - val_loss: 1.6157 - val_accuracy: 0.4357\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.7165 - val_loss: 1.7699 - val_accuracy: 0.4858\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.7272 - accuracy: 0.6871 - val_loss: 1.5814 - val_accuracy: 0.5075\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6749 - accuracy: 0.7061 - val_loss: 1.6877 - val_accuracy: 0.4825\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.6847 - accuracy: 0.7133 - val_loss: 1.5875 - val_accuracy: 0.5025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2c3f86cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLjPpSkGTD1c",
        "outputId": "e9d5dacf-59ab-4991-b589-edcf75d13410"
      },
      "source": [
        "vgg_features_test = pretrained_model.predict(x_test)\r\n",
        "\r\n",
        "predictions = model2.predict(vgg_features_test, verbose=1)\r\n",
        "\r\n",
        "y_true, y_pred = [],[]\r\n",
        "classes = encoder.classes_\r\n",
        "for idx, prediction in enumerate(predictions): \r\n",
        "    y_true.append(classes[np.argmax(y_test[idx])])\r\n",
        "    y_pred.append(classes[np.argmax(prediction)])\r\n",
        "    \r\n",
        "print(classification_report(y_pred, y_true))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AK       0.53      0.54      0.54        78\n",
            "         BCC       0.57      0.64      0.60        99\n",
            "         BKL       0.47      0.49      0.48       101\n",
            "          DF       0.52      0.57      0.54        30\n",
            "         MEL       0.49      0.51      0.50        87\n",
            "          NV       0.57      0.52      0.55       109\n",
            "         SCC       0.61      0.51      0.55        71\n",
            "        VASC       0.77      0.71      0.74        24\n",
            "\n",
            "    accuracy                           0.54       599\n",
            "   macro avg       0.57      0.56      0.56       599\n",
            "weighted avg       0.55      0.54      0.54       599\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}